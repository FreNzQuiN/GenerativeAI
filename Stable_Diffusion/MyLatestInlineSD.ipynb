{
  "nbformat": 4,
  "nbformat_minor": 0,
  "metadata": {
    "colab": {
      "provenance": [],
      "gpuType": "T4",
      "include_colab_link": true
    },
    "kernelspec": {
      "name": "python3",
      "display_name": "Python 3"
    },
    "language_info": {
      "name": "python"
    },
    "accelerator": "GPU",
    "widgets": {
      "application/vnd.jupyter.widget-state+json": {
        "cbb650c5219643e0b98fe3c7b6385f01": {
          "model_module": "@jupyter-widgets/controls",
          "model_name": "HBoxModel",
          "model_module_version": "1.5.0",
          "state": {
            "_dom_classes": [],
            "_model_module": "@jupyter-widgets/controls",
            "_model_module_version": "1.5.0",
            "_model_name": "HBoxModel",
            "_view_count": null,
            "_view_module": "@jupyter-widgets/controls",
            "_view_module_version": "1.5.0",
            "_view_name": "HBoxView",
            "box_style": "",
            "children": [
              "IPY_MODEL_11d977597d4440b4954f5c1bab1233af",
              "IPY_MODEL_32ad2e7d946a46748812f459ece1e08d",
              "IPY_MODEL_5089da87c3254fc284cbed1bcf325279"
            ],
            "layout": "IPY_MODEL_74ee37cff9b041bb8daeaa9b80c54b69"
          }
        },
        "11d977597d4440b4954f5c1bab1233af": {
          "model_module": "@jupyter-widgets/controls",
          "model_name": "HTMLModel",
          "model_module_version": "1.5.0",
          "state": {
            "_dom_classes": [],
            "_model_module": "@jupyter-widgets/controls",
            "_model_module_version": "1.5.0",
            "_model_name": "HTMLModel",
            "_view_count": null,
            "_view_module": "@jupyter-widgets/controls",
            "_view_module_version": "1.5.0",
            "_view_name": "HTMLView",
            "description": "",
            "description_tooltip": null,
            "layout": "IPY_MODEL_f7ba5a6df501457aada830d01dee23e0",
            "placeholder": "​",
            "style": "IPY_MODEL_df1bc6760c894a62b5fae3a12fd8dbbf",
            "value": "Loading pipeline components...: 100%"
          }
        },
        "32ad2e7d946a46748812f459ece1e08d": {
          "model_module": "@jupyter-widgets/controls",
          "model_name": "FloatProgressModel",
          "model_module_version": "1.5.0",
          "state": {
            "_dom_classes": [],
            "_model_module": "@jupyter-widgets/controls",
            "_model_module_version": "1.5.0",
            "_model_name": "FloatProgressModel",
            "_view_count": null,
            "_view_module": "@jupyter-widgets/controls",
            "_view_module_version": "1.5.0",
            "_view_name": "ProgressView",
            "bar_style": "success",
            "description": "",
            "description_tooltip": null,
            "layout": "IPY_MODEL_4beeaa9b71774c43aef3655d81d9f7a4",
            "max": 7,
            "min": 0,
            "orientation": "horizontal",
            "style": "IPY_MODEL_1b83b51baf924338aa0b7ecb294ec4b1",
            "value": 7
          }
        },
        "5089da87c3254fc284cbed1bcf325279": {
          "model_module": "@jupyter-widgets/controls",
          "model_name": "HTMLModel",
          "model_module_version": "1.5.0",
          "state": {
            "_dom_classes": [],
            "_model_module": "@jupyter-widgets/controls",
            "_model_module_version": "1.5.0",
            "_model_name": "HTMLModel",
            "_view_count": null,
            "_view_module": "@jupyter-widgets/controls",
            "_view_module_version": "1.5.0",
            "_view_name": "HTMLView",
            "description": "",
            "description_tooltip": null,
            "layout": "IPY_MODEL_06ad10f3ee6b4c5e966aecd8cc2f5727",
            "placeholder": "​",
            "style": "IPY_MODEL_a08e9a6bd4db41f9b0f5ec12aba69fc4",
            "value": " 7/7 [00:00&lt;00:00,  7.72it/s]"
          }
        },
        "74ee37cff9b041bb8daeaa9b80c54b69": {
          "model_module": "@jupyter-widgets/base",
          "model_name": "LayoutModel",
          "model_module_version": "1.2.0",
          "state": {
            "_model_module": "@jupyter-widgets/base",
            "_model_module_version": "1.2.0",
            "_model_name": "LayoutModel",
            "_view_count": null,
            "_view_module": "@jupyter-widgets/base",
            "_view_module_version": "1.2.0",
            "_view_name": "LayoutView",
            "align_content": null,
            "align_items": null,
            "align_self": null,
            "border": null,
            "bottom": null,
            "display": null,
            "flex": null,
            "flex_flow": null,
            "grid_area": null,
            "grid_auto_columns": null,
            "grid_auto_flow": null,
            "grid_auto_rows": null,
            "grid_column": null,
            "grid_gap": null,
            "grid_row": null,
            "grid_template_areas": null,
            "grid_template_columns": null,
            "grid_template_rows": null,
            "height": null,
            "justify_content": null,
            "justify_items": null,
            "left": null,
            "margin": null,
            "max_height": null,
            "max_width": null,
            "min_height": null,
            "min_width": null,
            "object_fit": null,
            "object_position": null,
            "order": null,
            "overflow": null,
            "overflow_x": null,
            "overflow_y": null,
            "padding": null,
            "right": null,
            "top": null,
            "visibility": null,
            "width": null
          }
        },
        "f7ba5a6df501457aada830d01dee23e0": {
          "model_module": "@jupyter-widgets/base",
          "model_name": "LayoutModel",
          "model_module_version": "1.2.0",
          "state": {
            "_model_module": "@jupyter-widgets/base",
            "_model_module_version": "1.2.0",
            "_model_name": "LayoutModel",
            "_view_count": null,
            "_view_module": "@jupyter-widgets/base",
            "_view_module_version": "1.2.0",
            "_view_name": "LayoutView",
            "align_content": null,
            "align_items": null,
            "align_self": null,
            "border": null,
            "bottom": null,
            "display": null,
            "flex": null,
            "flex_flow": null,
            "grid_area": null,
            "grid_auto_columns": null,
            "grid_auto_flow": null,
            "grid_auto_rows": null,
            "grid_column": null,
            "grid_gap": null,
            "grid_row": null,
            "grid_template_areas": null,
            "grid_template_columns": null,
            "grid_template_rows": null,
            "height": null,
            "justify_content": null,
            "justify_items": null,
            "left": null,
            "margin": null,
            "max_height": null,
            "max_width": null,
            "min_height": null,
            "min_width": null,
            "object_fit": null,
            "object_position": null,
            "order": null,
            "overflow": null,
            "overflow_x": null,
            "overflow_y": null,
            "padding": null,
            "right": null,
            "top": null,
            "visibility": null,
            "width": null
          }
        },
        "df1bc6760c894a62b5fae3a12fd8dbbf": {
          "model_module": "@jupyter-widgets/controls",
          "model_name": "DescriptionStyleModel",
          "model_module_version": "1.5.0",
          "state": {
            "_model_module": "@jupyter-widgets/controls",
            "_model_module_version": "1.5.0",
            "_model_name": "DescriptionStyleModel",
            "_view_count": null,
            "_view_module": "@jupyter-widgets/base",
            "_view_module_version": "1.2.0",
            "_view_name": "StyleView",
            "description_width": ""
          }
        },
        "4beeaa9b71774c43aef3655d81d9f7a4": {
          "model_module": "@jupyter-widgets/base",
          "model_name": "LayoutModel",
          "model_module_version": "1.2.0",
          "state": {
            "_model_module": "@jupyter-widgets/base",
            "_model_module_version": "1.2.0",
            "_model_name": "LayoutModel",
            "_view_count": null,
            "_view_module": "@jupyter-widgets/base",
            "_view_module_version": "1.2.0",
            "_view_name": "LayoutView",
            "align_content": null,
            "align_items": null,
            "align_self": null,
            "border": null,
            "bottom": null,
            "display": null,
            "flex": null,
            "flex_flow": null,
            "grid_area": null,
            "grid_auto_columns": null,
            "grid_auto_flow": null,
            "grid_auto_rows": null,
            "grid_column": null,
            "grid_gap": null,
            "grid_row": null,
            "grid_template_areas": null,
            "grid_template_columns": null,
            "grid_template_rows": null,
            "height": null,
            "justify_content": null,
            "justify_items": null,
            "left": null,
            "margin": null,
            "max_height": null,
            "max_width": null,
            "min_height": null,
            "min_width": null,
            "object_fit": null,
            "object_position": null,
            "order": null,
            "overflow": null,
            "overflow_x": null,
            "overflow_y": null,
            "padding": null,
            "right": null,
            "top": null,
            "visibility": null,
            "width": null
          }
        },
        "1b83b51baf924338aa0b7ecb294ec4b1": {
          "model_module": "@jupyter-widgets/controls",
          "model_name": "ProgressStyleModel",
          "model_module_version": "1.5.0",
          "state": {
            "_model_module": "@jupyter-widgets/controls",
            "_model_module_version": "1.5.0",
            "_model_name": "ProgressStyleModel",
            "_view_count": null,
            "_view_module": "@jupyter-widgets/base",
            "_view_module_version": "1.2.0",
            "_view_name": "StyleView",
            "bar_color": null,
            "description_width": ""
          }
        },
        "06ad10f3ee6b4c5e966aecd8cc2f5727": {
          "model_module": "@jupyter-widgets/base",
          "model_name": "LayoutModel",
          "model_module_version": "1.2.0",
          "state": {
            "_model_module": "@jupyter-widgets/base",
            "_model_module_version": "1.2.0",
            "_model_name": "LayoutModel",
            "_view_count": null,
            "_view_module": "@jupyter-widgets/base",
            "_view_module_version": "1.2.0",
            "_view_name": "LayoutView",
            "align_content": null,
            "align_items": null,
            "align_self": null,
            "border": null,
            "bottom": null,
            "display": null,
            "flex": null,
            "flex_flow": null,
            "grid_area": null,
            "grid_auto_columns": null,
            "grid_auto_flow": null,
            "grid_auto_rows": null,
            "grid_column": null,
            "grid_gap": null,
            "grid_row": null,
            "grid_template_areas": null,
            "grid_template_columns": null,
            "grid_template_rows": null,
            "height": null,
            "justify_content": null,
            "justify_items": null,
            "left": null,
            "margin": null,
            "max_height": null,
            "max_width": null,
            "min_height": null,
            "min_width": null,
            "object_fit": null,
            "object_position": null,
            "order": null,
            "overflow": null,
            "overflow_x": null,
            "overflow_y": null,
            "padding": null,
            "right": null,
            "top": null,
            "visibility": null,
            "width": null
          }
        },
        "a08e9a6bd4db41f9b0f5ec12aba69fc4": {
          "model_module": "@jupyter-widgets/controls",
          "model_name": "DescriptionStyleModel",
          "model_module_version": "1.5.0",
          "state": {
            "_model_module": "@jupyter-widgets/controls",
            "_model_module_version": "1.5.0",
            "_model_name": "DescriptionStyleModel",
            "_view_count": null,
            "_view_module": "@jupyter-widgets/base",
            "_view_module_version": "1.2.0",
            "_view_name": "StyleView",
            "description_width": ""
          }
        },
        "2c417685ad0141358b630152616559da": {
          "model_module": "@jupyter-widgets/controls",
          "model_name": "HBoxModel",
          "model_module_version": "1.5.0",
          "state": {
            "_dom_classes": [],
            "_model_module": "@jupyter-widgets/controls",
            "_model_module_version": "1.5.0",
            "_model_name": "HBoxModel",
            "_view_count": null,
            "_view_module": "@jupyter-widgets/controls",
            "_view_module_version": "1.5.0",
            "_view_name": "HBoxView",
            "box_style": "",
            "children": [
              "IPY_MODEL_ff3a2b2811474ae7804df1577eac4fd9",
              "IPY_MODEL_f93b47d9b24e40e590d3810be57bac1a",
              "IPY_MODEL_713a1a289801464594920f249e4071f7"
            ],
            "layout": "IPY_MODEL_23f4c7e32100478498870d34ddf53be9"
          }
        },
        "ff3a2b2811474ae7804df1577eac4fd9": {
          "model_module": "@jupyter-widgets/controls",
          "model_name": "HTMLModel",
          "model_module_version": "1.5.0",
          "state": {
            "_dom_classes": [],
            "_model_module": "@jupyter-widgets/controls",
            "_model_module_version": "1.5.0",
            "_model_name": "HTMLModel",
            "_view_count": null,
            "_view_module": "@jupyter-widgets/controls",
            "_view_module_version": "1.5.0",
            "_view_name": "HTMLView",
            "description": "",
            "description_tooltip": null,
            "layout": "IPY_MODEL_2a6fa57962084e579f7428b4b1baecf7",
            "placeholder": "​",
            "style": "IPY_MODEL_b13370265b884e2b864359180cf8ce53",
            "value": "  0%"
          }
        },
        "f93b47d9b24e40e590d3810be57bac1a": {
          "model_module": "@jupyter-widgets/controls",
          "model_name": "FloatProgressModel",
          "model_module_version": "1.5.0",
          "state": {
            "_dom_classes": [],
            "_model_module": "@jupyter-widgets/controls",
            "_model_module_version": "1.5.0",
            "_model_name": "FloatProgressModel",
            "_view_count": null,
            "_view_module": "@jupyter-widgets/controls",
            "_view_module_version": "1.5.0",
            "_view_name": "ProgressView",
            "bar_style": "danger",
            "description": "",
            "description_tooltip": null,
            "layout": "IPY_MODEL_2e590865456943daaf476e3c74fdaba6",
            "max": 26,
            "min": 0,
            "orientation": "horizontal",
            "style": "IPY_MODEL_4eec0cfcff5b44a6998c80839f6553f8",
            "value": 0
          }
        },
        "713a1a289801464594920f249e4071f7": {
          "model_module": "@jupyter-widgets/controls",
          "model_name": "HTMLModel",
          "model_module_version": "1.5.0",
          "state": {
            "_dom_classes": [],
            "_model_module": "@jupyter-widgets/controls",
            "_model_module_version": "1.5.0",
            "_model_name": "HTMLModel",
            "_view_count": null,
            "_view_module": "@jupyter-widgets/controls",
            "_view_module_version": "1.5.0",
            "_view_name": "HTMLView",
            "description": "",
            "description_tooltip": null,
            "layout": "IPY_MODEL_aed94c7610584a9fb96e6b849ae89261",
            "placeholder": "​",
            "style": "IPY_MODEL_0a9e27f96d5a435686a13118da26bae5",
            "value": " 0/26 [00:00&lt;?, ?it/s]"
          }
        },
        "23f4c7e32100478498870d34ddf53be9": {
          "model_module": "@jupyter-widgets/base",
          "model_name": "LayoutModel",
          "model_module_version": "1.2.0",
          "state": {
            "_model_module": "@jupyter-widgets/base",
            "_model_module_version": "1.2.0",
            "_model_name": "LayoutModel",
            "_view_count": null,
            "_view_module": "@jupyter-widgets/base",
            "_view_module_version": "1.2.0",
            "_view_name": "LayoutView",
            "align_content": null,
            "align_items": null,
            "align_self": null,
            "border": null,
            "bottom": null,
            "display": null,
            "flex": null,
            "flex_flow": null,
            "grid_area": null,
            "grid_auto_columns": null,
            "grid_auto_flow": null,
            "grid_auto_rows": null,
            "grid_column": null,
            "grid_gap": null,
            "grid_row": null,
            "grid_template_areas": null,
            "grid_template_columns": null,
            "grid_template_rows": null,
            "height": null,
            "justify_content": null,
            "justify_items": null,
            "left": null,
            "margin": null,
            "max_height": null,
            "max_width": null,
            "min_height": null,
            "min_width": null,
            "object_fit": null,
            "object_position": null,
            "order": null,
            "overflow": null,
            "overflow_x": null,
            "overflow_y": null,
            "padding": null,
            "right": null,
            "top": null,
            "visibility": null,
            "width": null
          }
        },
        "2a6fa57962084e579f7428b4b1baecf7": {
          "model_module": "@jupyter-widgets/base",
          "model_name": "LayoutModel",
          "model_module_version": "1.2.0",
          "state": {
            "_model_module": "@jupyter-widgets/base",
            "_model_module_version": "1.2.0",
            "_model_name": "LayoutModel",
            "_view_count": null,
            "_view_module": "@jupyter-widgets/base",
            "_view_module_version": "1.2.0",
            "_view_name": "LayoutView",
            "align_content": null,
            "align_items": null,
            "align_self": null,
            "border": null,
            "bottom": null,
            "display": null,
            "flex": null,
            "flex_flow": null,
            "grid_area": null,
            "grid_auto_columns": null,
            "grid_auto_flow": null,
            "grid_auto_rows": null,
            "grid_column": null,
            "grid_gap": null,
            "grid_row": null,
            "grid_template_areas": null,
            "grid_template_columns": null,
            "grid_template_rows": null,
            "height": null,
            "justify_content": null,
            "justify_items": null,
            "left": null,
            "margin": null,
            "max_height": null,
            "max_width": null,
            "min_height": null,
            "min_width": null,
            "object_fit": null,
            "object_position": null,
            "order": null,
            "overflow": null,
            "overflow_x": null,
            "overflow_y": null,
            "padding": null,
            "right": null,
            "top": null,
            "visibility": null,
            "width": null
          }
        },
        "b13370265b884e2b864359180cf8ce53": {
          "model_module": "@jupyter-widgets/controls",
          "model_name": "DescriptionStyleModel",
          "model_module_version": "1.5.0",
          "state": {
            "_model_module": "@jupyter-widgets/controls",
            "_model_module_version": "1.5.0",
            "_model_name": "DescriptionStyleModel",
            "_view_count": null,
            "_view_module": "@jupyter-widgets/base",
            "_view_module_version": "1.2.0",
            "_view_name": "StyleView",
            "description_width": ""
          }
        },
        "2e590865456943daaf476e3c74fdaba6": {
          "model_module": "@jupyter-widgets/base",
          "model_name": "LayoutModel",
          "model_module_version": "1.2.0",
          "state": {
            "_model_module": "@jupyter-widgets/base",
            "_model_module_version": "1.2.0",
            "_model_name": "LayoutModel",
            "_view_count": null,
            "_view_module": "@jupyter-widgets/base",
            "_view_module_version": "1.2.0",
            "_view_name": "LayoutView",
            "align_content": null,
            "align_items": null,
            "align_self": null,
            "border": null,
            "bottom": null,
            "display": null,
            "flex": null,
            "flex_flow": null,
            "grid_area": null,
            "grid_auto_columns": null,
            "grid_auto_flow": null,
            "grid_auto_rows": null,
            "grid_column": null,
            "grid_gap": null,
            "grid_row": null,
            "grid_template_areas": null,
            "grid_template_columns": null,
            "grid_template_rows": null,
            "height": null,
            "justify_content": null,
            "justify_items": null,
            "left": null,
            "margin": null,
            "max_height": null,
            "max_width": null,
            "min_height": null,
            "min_width": null,
            "object_fit": null,
            "object_position": null,
            "order": null,
            "overflow": null,
            "overflow_x": null,
            "overflow_y": null,
            "padding": null,
            "right": null,
            "top": null,
            "visibility": null,
            "width": null
          }
        },
        "4eec0cfcff5b44a6998c80839f6553f8": {
          "model_module": "@jupyter-widgets/controls",
          "model_name": "ProgressStyleModel",
          "model_module_version": "1.5.0",
          "state": {
            "_model_module": "@jupyter-widgets/controls",
            "_model_module_version": "1.5.0",
            "_model_name": "ProgressStyleModel",
            "_view_count": null,
            "_view_module": "@jupyter-widgets/base",
            "_view_module_version": "1.2.0",
            "_view_name": "StyleView",
            "bar_color": null,
            "description_width": ""
          }
        },
        "aed94c7610584a9fb96e6b849ae89261": {
          "model_module": "@jupyter-widgets/base",
          "model_name": "LayoutModel",
          "model_module_version": "1.2.0",
          "state": {
            "_model_module": "@jupyter-widgets/base",
            "_model_module_version": "1.2.0",
            "_model_name": "LayoutModel",
            "_view_count": null,
            "_view_module": "@jupyter-widgets/base",
            "_view_module_version": "1.2.0",
            "_view_name": "LayoutView",
            "align_content": null,
            "align_items": null,
            "align_self": null,
            "border": null,
            "bottom": null,
            "display": null,
            "flex": null,
            "flex_flow": null,
            "grid_area": null,
            "grid_auto_columns": null,
            "grid_auto_flow": null,
            "grid_auto_rows": null,
            "grid_column": null,
            "grid_gap": null,
            "grid_row": null,
            "grid_template_areas": null,
            "grid_template_columns": null,
            "grid_template_rows": null,
            "height": null,
            "justify_content": null,
            "justify_items": null,
            "left": null,
            "margin": null,
            "max_height": null,
            "max_width": null,
            "min_height": null,
            "min_width": null,
            "object_fit": null,
            "object_position": null,
            "order": null,
            "overflow": null,
            "overflow_x": null,
            "overflow_y": null,
            "padding": null,
            "right": null,
            "top": null,
            "visibility": null,
            "width": null
          }
        },
        "0a9e27f96d5a435686a13118da26bae5": {
          "model_module": "@jupyter-widgets/controls",
          "model_name": "DescriptionStyleModel",
          "model_module_version": "1.5.0",
          "state": {
            "_model_module": "@jupyter-widgets/controls",
            "_model_module_version": "1.5.0",
            "_model_name": "DescriptionStyleModel",
            "_view_count": null,
            "_view_module": "@jupyter-widgets/base",
            "_view_module_version": "1.2.0",
            "_view_name": "StyleView",
            "description_width": ""
          }
        }
      }
    }
  },
  "cells": [
    {
      "cell_type": "markdown",
      "metadata": {
        "id": "view-in-github",
        "colab_type": "text"
      },
      "source": [
        "<a href=\"https://colab.research.google.com/github/FreNzQuiN/GenerativeAI/blob/main/Stable_Diffusion/MyLatestInlineSD.ipynb\" target=\"_parent\"><img src=\"https://colab.research.google.com/assets/colab-badge.svg\" alt=\"Open In Colab\"/></a>"
      ]
    },
    {
      "cell_type": "markdown",
      "source": [
        "# **1.1 START -- TEXT2IMG SD**"
      ],
      "metadata": {
        "id": "D3p5A4NPiKIN"
      }
    },
    {
      "cell_type": "code",
      "source": [
        "!pip install -q diffusers transformers accelerate safetensors compel # --upgrade\n",
        "import torch\n",
        "from torch import autocast\n",
        "from diffusers import StableDiffusionXLPipeline\n",
        "from compel import Compel, ReturnedEmbeddingsType\n",
        "import matplotlib.pyplot as plt\n",
        "from PIL import Image, ImageFilter\n",
        "import random, time, math, os\n",
        "import torch, gc\n",
        "from tqdm import tqdm\n",
        "import requests\n",
        "from io import BytesIO\n",
        "\n",
        "if not os.path.exists(\"scheduler_config.json\"):\n",
        "  !wget https://huggingface.co/cagliostrolab/animagine-xl-4.0/resolve/main/scheduler/scheduler_config.json\n",
        "\n",
        "custom_config = True #@param {type:'boolean'}\n",
        "if os.path.exists(\"scheduler_config.json\") and not custom_config:\n",
        "  with open(\"scheduler_config.json\", \"r\") as f:\n",
        "    scheduler_config = json.load(f)\n",
        "else:\n",
        "  scheduler_config = {\n",
        "    \"beta_start\": 0.00085,\n",
        "    \"beta_end\": 0.012,\n",
        "    \"num_train_timesteps\": 1000,\n",
        "    \"steps_offset\" : 2,\n",
        "    \"beta_schedule\": \"scaled_linear\",\n",
        "    \"clip_sample\": False,\n",
        "    \"set_alpha_to_one\": False,\n",
        "    \"_class_name\": \"DDIMScheduler\",\n",
        "    \"_diffusers_version\": \"0.32.2\"\n",
        "  }\n",
        "\n",
        "#@markdown ## **Scheduler**\n",
        "SCHEDULER = \"KDPM2AncestralDiscreteScheduler\" # @param [\"DDIMScheduler\",\"EulerAncestralDiscreteScheduler\",\"DPMSolverSDEScheduler\",\"KDPM2AncestralDiscreteScheduler\",\"PNDMScheduler\"]\n",
        "\n",
        "!pip install hf_xet\n",
        "pipe = StableDiffusionXLPipeline.from_pretrained(\n",
        "    \"cagliostrolab/animagine-xl-4.0\",\n",
        "    torch_dtype=torch.float16,\n",
        "    use_safetensors=True,\n",
        "    custom_pipeline=\"lpw_stable_diffusion_xl\",\n",
        "    add_watermarker=False,\n",
        "    )\n",
        "\n",
        "if SCHEDULER == \"EulerAncestralDiscreteScheduler\":\n",
        "  from diffusers import EulerAncestralDiscreteScheduler\n",
        "  pipe.scheduler = EulerAncestralDiscreteScheduler.from_config(scheduler_config)\n",
        "elif SCHEDULER == \"DDIMScheduler\":\n",
        "  from diffusers import DDIMScheduler\n",
        "  pipe.scheduler = DDIMScheduler.from_config(scheduler_config)\n",
        "elif SCHEDULER == \"DPMSolverSDEScheduler\":\n",
        "    from diffusers import DPMSolverSDEScheduler\n",
        "    pipe.scheduler = DPMSolverSDEScheduler.from_config(scheduler_config)\n",
        "elif SCHEDULER == \"KDPM2AncestralDiscreteScheduler\":\n",
        "    from diffusers import KDPM2AncestralDiscreteScheduler\n",
        "    pipe.scheduler = KDPM2AncestralDiscreteScheduler.from_config(scheduler_config)\n",
        "elif SCHEDULER == \"PNDMScheduler\":\n",
        "    from diffusers import PNDMScheduler\n",
        "    pipe.scheduler = PNDMScheduler.from_config(scheduler_config)\n",
        "\n",
        "pipe.to('cuda')\n",
        "\n",
        "!curl -o wd14-tagger.py https://raw.githubusercontent.com/FreNzQuiN/GenerativeAI/refs/heads/main/Stable_Diffusion/wd14-tagger.py"
      ],
      "metadata": {
        "id": "yOZXfJRCqFg0",
        "outputId": "cea8589a-9fbf-40be-a79c-5a1d1b50757f",
        "colab": {
          "base_uri": "https://localhost:8080/",
          "height": 900,
          "referenced_widgets": [
            "cbb650c5219643e0b98fe3c7b6385f01",
            "11d977597d4440b4954f5c1bab1233af",
            "32ad2e7d946a46748812f459ece1e08d",
            "5089da87c3254fc284cbed1bcf325279",
            "74ee37cff9b041bb8daeaa9b80c54b69",
            "f7ba5a6df501457aada830d01dee23e0",
            "df1bc6760c894a62b5fae3a12fd8dbbf",
            "4beeaa9b71774c43aef3655d81d9f7a4",
            "1b83b51baf924338aa0b7ecb294ec4b1",
            "06ad10f3ee6b4c5e966aecd8cc2f5727",
            "a08e9a6bd4db41f9b0f5ec12aba69fc4"
          ]
        }
      },
      "execution_count": 81,
      "outputs": [
        {
          "output_type": "stream",
          "name": "stdout",
          "text": [
            "Requirement already satisfied: diffusers in /usr/local/lib/python3.11/dist-packages (0.33.1)\n",
            "Requirement already satisfied: transformers in /usr/local/lib/python3.11/dist-packages (4.51.3)\n",
            "Requirement already satisfied: accelerate in /usr/local/lib/python3.11/dist-packages (1.6.0)\n",
            "Requirement already satisfied: safetensors in /usr/local/lib/python3.11/dist-packages (0.5.3)\n",
            "Requirement already satisfied: compel in /usr/local/lib/python3.11/dist-packages (2.0.3)\n",
            "Requirement already satisfied: importlib-metadata in /usr/local/lib/python3.11/dist-packages (from diffusers) (8.7.0)\n",
            "Requirement already satisfied: filelock in /usr/local/lib/python3.11/dist-packages (from diffusers) (3.18.0)\n",
            "Requirement already satisfied: huggingface-hub>=0.27.0 in /usr/local/lib/python3.11/dist-packages (from diffusers) (0.30.2)\n",
            "Requirement already satisfied: numpy in /usr/local/lib/python3.11/dist-packages (from diffusers) (2.0.2)\n",
            "Requirement already satisfied: regex!=2019.12.17 in /usr/local/lib/python3.11/dist-packages (from diffusers) (2024.11.6)\n",
            "Requirement already satisfied: requests in /usr/local/lib/python3.11/dist-packages (from diffusers) (2.32.3)\n",
            "Requirement already satisfied: Pillow in /usr/local/lib/python3.11/dist-packages (from diffusers) (11.2.1)\n",
            "Requirement already satisfied: packaging>=20.0 in /usr/local/lib/python3.11/dist-packages (from transformers) (24.2)\n",
            "Requirement already satisfied: pyyaml>=5.1 in /usr/local/lib/python3.11/dist-packages (from transformers) (6.0.2)\n",
            "Requirement already satisfied: tokenizers<0.22,>=0.21 in /usr/local/lib/python3.11/dist-packages (from transformers) (0.21.1)\n",
            "Requirement already satisfied: tqdm>=4.27 in /usr/local/lib/python3.11/dist-packages (from transformers) (4.67.1)\n",
            "Requirement already satisfied: psutil in /usr/local/lib/python3.11/dist-packages (from accelerate) (5.9.5)\n",
            "Requirement already satisfied: torch>=2.0.0 in /usr/local/lib/python3.11/dist-packages (from accelerate) (2.6.0+cu124)\n",
            "Requirement already satisfied: pyparsing~=3.0 in /usr/local/lib/python3.11/dist-packages (from compel) (3.2.3)\n",
            "Requirement already satisfied: fsspec>=2023.5.0 in /usr/local/lib/python3.11/dist-packages (from huggingface-hub>=0.27.0->diffusers) (2025.3.2)\n",
            "Requirement already satisfied: typing-extensions>=3.7.4.3 in /usr/local/lib/python3.11/dist-packages (from huggingface-hub>=0.27.0->diffusers) (4.13.2)\n",
            "Requirement already satisfied: networkx in /usr/local/lib/python3.11/dist-packages (from torch>=2.0.0->accelerate) (3.4.2)\n",
            "Requirement already satisfied: jinja2 in /usr/local/lib/python3.11/dist-packages (from torch>=2.0.0->accelerate) (3.1.6)\n",
            "Requirement already satisfied: nvidia-cuda-nvrtc-cu12==12.4.127 in /usr/local/lib/python3.11/dist-packages (from torch>=2.0.0->accelerate) (12.4.127)\n",
            "Requirement already satisfied: nvidia-cuda-runtime-cu12==12.4.127 in /usr/local/lib/python3.11/dist-packages (from torch>=2.0.0->accelerate) (12.4.127)\n",
            "Requirement already satisfied: nvidia-cuda-cupti-cu12==12.4.127 in /usr/local/lib/python3.11/dist-packages (from torch>=2.0.0->accelerate) (12.4.127)\n",
            "Requirement already satisfied: nvidia-cudnn-cu12==9.1.0.70 in /usr/local/lib/python3.11/dist-packages (from torch>=2.0.0->accelerate) (9.1.0.70)\n",
            "Requirement already satisfied: nvidia-cublas-cu12==12.4.5.8 in /usr/local/lib/python3.11/dist-packages (from torch>=2.0.0->accelerate) (12.4.5.8)\n",
            "Requirement already satisfied: nvidia-cufft-cu12==11.2.1.3 in /usr/local/lib/python3.11/dist-packages (from torch>=2.0.0->accelerate) (11.2.1.3)\n",
            "Requirement already satisfied: nvidia-curand-cu12==10.3.5.147 in /usr/local/lib/python3.11/dist-packages (from torch>=2.0.0->accelerate) (10.3.5.147)\n",
            "Requirement already satisfied: nvidia-cusolver-cu12==11.6.1.9 in /usr/local/lib/python3.11/dist-packages (from torch>=2.0.0->accelerate) (11.6.1.9)\n",
            "Requirement already satisfied: nvidia-cusparse-cu12==12.3.1.170 in /usr/local/lib/python3.11/dist-packages (from torch>=2.0.0->accelerate) (12.3.1.170)\n",
            "Requirement already satisfied: nvidia-cusparselt-cu12==0.6.2 in /usr/local/lib/python3.11/dist-packages (from torch>=2.0.0->accelerate) (0.6.2)\n",
            "Requirement already satisfied: nvidia-nccl-cu12==2.21.5 in /usr/local/lib/python3.11/dist-packages (from torch>=2.0.0->accelerate) (2.21.5)\n",
            "Requirement already satisfied: nvidia-nvtx-cu12==12.4.127 in /usr/local/lib/python3.11/dist-packages (from torch>=2.0.0->accelerate) (12.4.127)\n",
            "Requirement already satisfied: nvidia-nvjitlink-cu12==12.4.127 in /usr/local/lib/python3.11/dist-packages (from torch>=2.0.0->accelerate) (12.4.127)\n",
            "Requirement already satisfied: triton==3.2.0 in /usr/local/lib/python3.11/dist-packages (from torch>=2.0.0->accelerate) (3.2.0)\n",
            "Requirement already satisfied: sympy==1.13.1 in /usr/local/lib/python3.11/dist-packages (from torch>=2.0.0->accelerate) (1.13.1)\n",
            "Requirement already satisfied: mpmath<1.4,>=1.1.0 in /usr/local/lib/python3.11/dist-packages (from sympy==1.13.1->torch>=2.0.0->accelerate) (1.3.0)\n",
            "Requirement already satisfied: zipp>=3.20 in /usr/local/lib/python3.11/dist-packages (from importlib-metadata->diffusers) (3.21.0)\n",
            "Requirement already satisfied: charset-normalizer<4,>=2 in /usr/local/lib/python3.11/dist-packages (from requests->diffusers) (3.4.1)\n",
            "Requirement already satisfied: idna<4,>=2.5 in /usr/local/lib/python3.11/dist-packages (from requests->diffusers) (3.10)\n",
            "Requirement already satisfied: urllib3<3,>=1.21.1 in /usr/local/lib/python3.11/dist-packages (from requests->diffusers) (2.4.0)\n",
            "Requirement already satisfied: certifi>=2017.4.17 in /usr/local/lib/python3.11/dist-packages (from requests->diffusers) (2025.4.26)\n",
            "Requirement already satisfied: MarkupSafe>=2.0 in /usr/local/lib/python3.11/dist-packages (from jinja2->torch>=2.0.0->accelerate) (3.0.2)\n",
            "Requirement already satisfied: hf_xet in /usr/local/lib/python3.11/dist-packages (1.1.0)\n"
          ]
        },
        {
          "output_type": "display_data",
          "data": {
            "text/plain": [
              "Loading pipeline components...:   0%|          | 0/7 [00:00<?, ?it/s]"
            ],
            "application/vnd.jupyter.widget-view+json": {
              "version_major": 2,
              "version_minor": 0,
              "model_id": "cbb650c5219643e0b98fe3c7b6385f01"
            }
          },
          "metadata": {}
        },
        {
          "output_type": "stream",
          "name": "stdout",
          "text": [
            "  % Total    % Received % Xferd  Average Speed   Time    Time     Time  Current\n",
            "                                 Dload  Upload   Total   Spent    Left  Speed\n",
            "100  6820  100  6820    0     0  17956      0 --:--:-- --:--:-- --:--:-- 17947\n"
          ]
        }
      ]
    },
    {
      "cell_type": "code",
      "source": [
        "# download model\n",
        "!wget https://github.com/xinntao/Real-ESRGAN/releases/download/v0.2.2.4/RealESRGAN_x4plus_anime_6B.pth -P weights\n",
        "!curl inference_realesrgan.py -o https://raw.githubusercontent.com/xinntao/Real-ESRGAN/refs/heads/master/inference_realesrgan.py\n",
        "# inference\n",
        "!python inference_realesrgan.py -n RealESRGAN_x4plus_anime_6B -i inputs"
      ],
      "metadata": {
        "id": "bHBjDFFJHrAK",
        "outputId": "ddafa6d6-9c98-4913-ebdb-74fc323fb0d9",
        "colab": {
          "base_uri": "https://localhost:8080/"
        }
      },
      "execution_count": null,
      "outputs": [
        {
          "output_type": "stream",
          "name": "stdout",
          "text": [
            "--2025-05-02 22:49:12--  https://github.com/xinntao/Real-ESRGAN/releases/download/v0.2.2.4/RealESRGAN_x4plus_anime_6B.pth\n",
            "Resolving github.com (github.com)... 140.82.113.4\n",
            "Connecting to github.com (github.com)|140.82.113.4|:443... connected.\n",
            "HTTP request sent, awaiting response... 302 Found\n",
            "Location: https://objects.githubusercontent.com/github-production-release-asset-2e65be/387326890/4f59d7c8-d03f-494e-8595-ae23af075393?X-Amz-Algorithm=AWS4-HMAC-SHA256&X-Amz-Credential=releaseassetproduction%2F20250502%2Fus-east-1%2Fs3%2Faws4_request&X-Amz-Date=20250502T224751Z&X-Amz-Expires=300&X-Amz-Signature=87ae256e1afe25593f41f5942776df4f31ccc37cd9fa067e04d4a56ad121c301&X-Amz-SignedHeaders=host&response-content-disposition=attachment%3B%20filename%3DRealESRGAN_x4plus_anime_6B.pth&response-content-type=application%2Foctet-stream [following]\n",
            "--2025-05-02 22:49:12--  https://objects.githubusercontent.com/github-production-release-asset-2e65be/387326890/4f59d7c8-d03f-494e-8595-ae23af075393?X-Amz-Algorithm=AWS4-HMAC-SHA256&X-Amz-Credential=releaseassetproduction%2F20250502%2Fus-east-1%2Fs3%2Faws4_request&X-Amz-Date=20250502T224751Z&X-Amz-Expires=300&X-Amz-Signature=87ae256e1afe25593f41f5942776df4f31ccc37cd9fa067e04d4a56ad121c301&X-Amz-SignedHeaders=host&response-content-disposition=attachment%3B%20filename%3DRealESRGAN_x4plus_anime_6B.pth&response-content-type=application%2Foctet-stream\n",
            "Resolving objects.githubusercontent.com (objects.githubusercontent.com)... 185.199.108.133, 185.199.111.133, 185.199.109.133, ...\n",
            "Connecting to objects.githubusercontent.com (objects.githubusercontent.com)|185.199.108.133|:443... connected.\n",
            "HTTP request sent, awaiting response... 200 OK\n",
            "Length: 17938799 (17M) [application/octet-stream]\n",
            "Saving to: ‘weights/RealESRGAN_x4plus_anime_6B.pth.4’\n",
            "\n",
            "RealESRGAN_x4plus_a 100%[===================>]  17.11M  --.-KB/s    in 0.08s   \n",
            "\n",
            "2025-05-02 22:49:12 (226 MB/s) - ‘weights/RealESRGAN_x4plus_anime_6B.pth.4’ saved [17938799/17938799]\n",
            "\n",
            "  % Total    % Received % Xferd  Average Speed   Time    Time     Time  Current\n",
            "                                 Dload  Upload   Total   Spent    Left  Speed\n",
            "  0     0    0     0    0     0      0      0 --:--:-- --:--:-- --:--:--     0curl: (6) Could not resolve host: inference_realesrgan.py\n",
            "python3: can't open file '/content/inference_realesrgan.py': [Errno 2] No such file or directory\n"
          ]
        }
      ]
    },
    {
      "cell_type": "code",
      "source": [
        "#@title #**1.2 START -- IMG2IMG SD**\n",
        "!pip install diffusers transformers accelerate safetensors compel --upgrade\n",
        "import torch\n",
        "from torch import autocast\n",
        "from diffusers import StableDiffusionXLPipeline, DDIMScheduler\n",
        "from compel import Compel, ReturnedEmbeddingsType\n",
        "import matplotlib.pyplot as plt\n",
        "from PIL import Image, ImageFilter\n",
        "import random, time, math, os\n",
        "import torch, gc\n",
        "from tqdm import tqdm\n",
        "import json\n",
        "import requests\n",
        "from io import BytesIO\n",
        "\n",
        "if not os.path.exists(\"scheduler_config.json\"):\n",
        "    !wget https://huggingface.co/cagliostrolab/animagine-xl-4.0/resolve/main/scheduler/scheduler_config.json\n",
        "\n",
        "custom_config = True  # @param {type:'boolean'}\n",
        "if os.path.exists(\"scheduler_config.json\") and not custom_config:\n",
        "    with open(\"scheduler_config.json\", \"r\") as f:\n",
        "        scheduler_config = json.load(f)\n",
        "else:\n",
        "    scheduler_config = {\n",
        "        \"beta_start\": 0.00085,\n",
        "        \"beta_end\": 0.012,\n",
        "        \"num_train_timesteps\": 1000,\n",
        "        \"steps_offset\": 2,\n",
        "        \"beta_schedule\": \"scaled_linear\",\n",
        "        \"clip_sample\": False,\n",
        "        \"set_alpha_to_one\": False,\n",
        "        \"_class_name\": \"DDIMScheduler\",\n",
        "        \"_diffusers_version\": \"0.32.2\"\n",
        "    }\n",
        "\n",
        "pipe = StableDiffusionXLPipeline.from_pretrained(\n",
        "    \"cagliostrolab/animagine-xl-4.0\",\n",
        "    torch_dtype=torch.float16,\n",
        "    use_safetensors=True,\n",
        "    custom_pipeline=\"lpw_stable_diffusion_xl\",\n",
        "    add_watermarker=False,\n",
        ")\n",
        "\n",
        "pipe.scheduler = DDIMScheduler.from_config(scheduler_config)\n",
        "pipe.to('cuda')"
      ],
      "metadata": {
        "id": "EgM8KpjQpmn9"
      },
      "execution_count": null,
      "outputs": []
    },
    {
      "cell_type": "code",
      "source": [
        "#@title #**2.1 PLAY TEXT2IMG SD**\n",
        "\n",
        "num=0\n",
        "prompt_num=0\n",
        "def disabled_safety_checker(images, clip_input):\n",
        "    if len(images.shape)==4:\n",
        "        num_images = images.shape[0]\n",
        "        return images, [False]*num_images\n",
        "    else:\n",
        "        return images, False\n",
        "pipe.safety_checker = disabled_safety_checker"
      ],
      "metadata": {
        "id": "TX5cV32X0-yJ",
        "outputId": "3fee4791-5870-44c6-df84-1775fd58a1d0",
        "colab": {
          "base_uri": "https://localhost:8080/"
        }
      },
      "execution_count": 2,
      "outputs": [
        {
          "output_type": "stream",
          "name": "stdout",
          "text": [
            "Collecting hf_xet\n",
            "  Downloading hf_xet-1.1.0-cp37-abi3-manylinux_2_17_x86_64.manylinux2014_x86_64.whl.metadata (494 bytes)\n",
            "Downloading hf_xet-1.1.0-cp37-abi3-manylinux_2_17_x86_64.manylinux2014_x86_64.whl (53.6 MB)\n",
            "\u001b[2K   \u001b[90m━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━\u001b[0m \u001b[32m53.6/53.6 MB\u001b[0m \u001b[31m14.0 MB/s\u001b[0m eta \u001b[36m0:00:00\u001b[0m\n",
            "\u001b[?25hInstalling collected packages: hf_xet\n",
            "Successfully installed hf_xet-1.1.0\n"
          ]
        }
      ]
    },
    {
      "cell_type": "code",
      "source": [
        "w = f\"/content/outputs\"\n",
        "if not os.path.exists(w):\n",
        "    os.makedirs(w)\n",
        "\n",
        "def generate_image(pipe, prompt, negative_prompt, output_path, width, height, guidance_scale, guidance_rescale, num_inference_steps, seed):\n",
        "    \"\"\"Menghasilkan gambar Stable Diffusion.\"\"\"\n",
        "    image = pipe(\n",
        "        prompt=prompt,\n",
        "        negative_prompt=negative_prompt,\n",
        "        seed=seed,\n",
        "        width=width,\n",
        "        height=height,\n",
        "        guidance_scale=guidance_scale,\n",
        "        guidance_rescale=guidance_rescale,\n",
        "        target_size=(width, height),\n",
        "        original_size=(4096, 4096),\n",
        "        num_inference_steps=num_inference_steps,\n",
        "        truncation=False,\n",
        "        clip_skip = 1\n",
        "    ).images[0]\n",
        "    image.save(output_path, \"png\", lossless=True, quality=100)\n",
        "    return image\n",
        "\n",
        "def upscale_anime_image(input_pil, output_path):\n",
        "    \"\"\"Upscale gambar PIL dengan RealESRGAN anime6B dan simpan hasilnya.\"\"\"\n",
        "    output, _ = upscaler.enhance(input_pil)\n",
        "    output.save(output_path)\n",
        "    return output\n",
        "\n",
        "def log_metadata(file_path, start_num, end_num, output_base, width, height, style, char, rating, desc_char, pov, bg, add, negative_prompt, guidance_scale, guidance_rescale, num_inference_steps, elapsed_time):\n",
        "    \"\"\"Mencatat metadata ke dalam file teks.\"\"\"\n",
        "    with open(file_path, \"a\") as text_file:\n",
        "        text_file.write(f\"\\n\\nTITLE: {start_num}--{end_num} {output_base} {width}x{height}px\\n + {style},\\n {char},\\n {rating},\\n {desc_char},\\n {pov},\\n {bg},\\n {add}\\n - {negative_prompt}\\n guide scale/rescale: {guidance_scale}/{guidance_rescale}\\n steps: {num_inference_steps}\\nIt took {math.floor(elapsed_time/60)} minutes {math.floor(elapsed_time%60)} seconds!\")\n",
        "\n",
        "amount = 3 #@param {type:'integer'}\n",
        "#@markdown ---\n",
        "lora = \"\" # @param {\"type\":\"string\"}\n",
        "style = \"masterpiece, best quality\" # @param {\"type\":\"string\",\"placeholder\":\"masterpiece, high score, best quality, amazing quality, absurdres, [vibrant, very aesthetic, high contrast], masterful composition\"}\n",
        "char = \"(1girl, goldenglow, arknights), long hair single braid, solo, \" #@param {type:\"string\"}\n",
        "rating = \"safe\" # @param [\"safe\",\"sensitive\"] {\"allow-input\":true}\n",
        "desc_char = \"blush, medium breast, cleavage, collarbone, slip\" #@param {type:'string'}\n",
        "pov = \"looking at viewer, from front, blurry\" # @param {\"type\":\"string\",\"placeholder\":\"dutch angle, looking at viewer, from front, depth of field, close up\"}\n",
        "bg = \"modern, indoors, dining room, pottet plant, soft/warm color\" # @param {\"type\":\"string\",\"placeholder\":\"colorful, indoors, natural scenery\"}\n",
        "add = \"high detail and beautiful eyes\" #@param {type:\"string\"}\n",
        "if rating == \"\":\n",
        "  ratingX=\"all\"\n",
        "#@markdown ---\n",
        "prompt = f\"{lora}, {style}, {char}, {rating}, {desc_char}, {pov}, {bg}, {add}\"\n",
        "negative_prompt = \"lowres, worst quality, bad quality, bad anatomy, jpeg artifacts, old, oldest, watermark, mosaic censoring, stripe, censored, normal quality, username\" #@param {type:'string'}\n",
        "\n",
        "#@markdown ---\n",
        "W = 1024 #@param {type:\"slider\", min:512, max:2048, step:32}\n",
        "H = 1280 #@param {type:\"slider\", min:512, max:2048, step:32}\n",
        "swapWH = False # @param {\"type\":\"boolean\"}\n",
        "if swapWH:\n",
        "  W, H = H, W\n",
        "#@markdown ---\n",
        "guidance_scale = 6 #@param {type:'number'}\n",
        "guidance_rescale = 0.92 #@param {type:'number'}\n",
        "num_inference_steps = 26 #@param {type:\"slider\", min:10, max:40, step:1}\n",
        "#@markdown ---\n",
        "\n",
        "if len(char) > 10 or (char[:1] == \"(\" and char[-1:] == \")\"):\n",
        "    nama_char = char.split(\", \")[1].split(\" \")[0]\n",
        "    jenis_char = char.split(\", \")[0][1:]\n",
        "outputname = \"anime\" #@param {type:'string'}\n",
        "ratingX = rating.split(\" \")[0]\n",
        "\n",
        "outputbase = f\"/content/outputs/{nama_char}_{ratingX}/{outputname}_{jenis_char}\"\n",
        "w = f\"/content/outputs/{nama_char}_{ratingX}\"\n",
        "if not os.path.exists(w):\n",
        "    os.makedirs(w)\n",
        "rand = True #@param {type:'boolean'}\n",
        "if rand:\n",
        "    seed = 9999999 #@param {type:'integer'}\n",
        "startNum = num\n",
        "\n",
        "taggers = True #@param {type:'boolean'}\n",
        "\n",
        "start_time = time.time()\n",
        "array_time = []\n",
        "\n",
        "for x in tqdm(range(amount), desc=f\"Generating Images {num}\"):\n",
        "    gc.collect()\n",
        "    torch.cuda.empty_cache()\n",
        "    image_start_time = time.time()\n",
        "    if rand:\n",
        "        set_seed = random.randint(10, 1000000000)\n",
        "    else:\n",
        "        set_seed = seed\n",
        "    output_file = f\"{outputbase}_{num}_{set_seed}_{ratingX}.png\"\n",
        "    image = generate_image(pipe, prompt, negative_prompt, output_file, W, H, guidance_scale, guidance_rescale, num_inference_steps, set_seed)\n",
        "    blurred_image = image.filter(ImageFilter.GaussianBlur(radius=15))\n",
        "    plt.figure(figsize=(W/80, H/80))\n",
        "    if \"nsfw\" in rating or \"explicit\" in rating:\n",
        "      plt.imshow(blurred_image)\n",
        "    else :\n",
        "      plt.imshow(image)\n",
        "    plt.axis('off')\n",
        "    plt.show()\n",
        "    image_end_time = time.time()\n",
        "    array_time.append(image_end_time - image_start_time)\n",
        "    num += 1\n",
        "    if taggers:\n",
        "      !python /content/wd14-tagger.py \"{output_file}\" --output_file \"hasil_tag.txt\"\n",
        "\n",
        "end_time = time.time()\n",
        "total_time = end_time - start_time\n",
        "log_metadata(f\"prompt_{prompt_num}.txt\", startNum, num - 1, outputbase, W, H, style, char, rating, desc_char, pov, bg, add, negative_prompt, guidance_scale, guidance_rescale, num_inference_steps, total_time)\n",
        "\n",
        "gc.collect()\n",
        "torch.cuda.empty_cache()\n",
        "\n",
        "print(f\"It took {math.floor(total_time/60)} minutes {math.floor(total_time%60)} seconds!\")\n",
        "\n"
      ],
      "metadata": {
        "id": "8Ta3AnCph0Mb",
        "colab": {
          "base_uri": "https://localhost:8080/",
          "height": 458,
          "referenced_widgets": [
            "2c417685ad0141358b630152616559da",
            "ff3a2b2811474ae7804df1577eac4fd9",
            "f93b47d9b24e40e590d3810be57bac1a",
            "713a1a289801464594920f249e4071f7",
            "23f4c7e32100478498870d34ddf53be9",
            "2a6fa57962084e579f7428b4b1baecf7",
            "b13370265b884e2b864359180cf8ce53",
            "2e590865456943daaf476e3c74fdaba6",
            "4eec0cfcff5b44a6998c80839f6553f8",
            "aed94c7610584a9fb96e6b849ae89261",
            "0a9e27f96d5a435686a13118da26bae5"
          ]
        },
        "outputId": "c9b62a43-dacb-47c4-865f-8b19039b6d99",
        "cellView": "form"
      },
      "execution_count": 86,
      "outputs": [
        {
          "output_type": "stream",
          "name": "stderr",
          "text": [
            "\rGenerating Images 112:   0%|          | 0/3 [00:00<?, ?it/s]"
          ]
        },
        {
          "output_type": "display_data",
          "data": {
            "text/plain": [
              "  0%|          | 0/26 [00:00<?, ?it/s]"
            ],
            "application/vnd.jupyter.widget-view+json": {
              "version_major": 2,
              "version_minor": 0,
              "model_id": "2c417685ad0141358b630152616559da"
            }
          },
          "metadata": {}
        },
        {
          "output_type": "stream",
          "name": "stderr",
          "text": [
            "\rGenerating Images 112:   0%|          | 0/3 [00:01<?, ?it/s]\n"
          ]
        },
        {
          "output_type": "error",
          "ename": "OutOfMemoryError",
          "evalue": "CUDA out of memory. Tried to allocate 50.00 MiB. GPU 0 has a total capacity of 14.74 GiB of which 50.12 MiB is free. Process 2367 has 14.69 GiB memory in use. Of the allocated memory 14.04 GiB is allocated by PyTorch, and 534.33 MiB is reserved by PyTorch but unallocated. If reserved but unallocated memory is large try setting PYTORCH_CUDA_ALLOC_CONF=expandable_segments:True to avoid fragmentation.  See documentation for Memory Management  (https://pytorch.org/docs/stable/notes/cuda.html#environment-variables)",
          "traceback": [
            "\u001b[0;31m---------------------------------------------------------------------------\u001b[0m",
            "\u001b[0;31mOutOfMemoryError\u001b[0m                          Traceback (most recent call last)",
            "\u001b[0;32m<ipython-input-86-7cda760ae67e>\u001b[0m in \u001b[0;36m<cell line: 0>\u001b[0;34m()\u001b[0m\n\u001b[1;32m     90\u001b[0m         \u001b[0mset_seed\u001b[0m \u001b[0;34m=\u001b[0m \u001b[0mseed\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[1;32m     91\u001b[0m     \u001b[0moutput_file\u001b[0m \u001b[0;34m=\u001b[0m \u001b[0;34mf\"{outputbase}_{num}_{set_seed}_{ratingX}.png\"\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[0;32m---> 92\u001b[0;31m     \u001b[0mimage\u001b[0m \u001b[0;34m=\u001b[0m \u001b[0mgenerate_image\u001b[0m\u001b[0;34m(\u001b[0m\u001b[0mpipe\u001b[0m\u001b[0;34m,\u001b[0m \u001b[0mprompt\u001b[0m\u001b[0;34m,\u001b[0m \u001b[0mnegative_prompt\u001b[0m\u001b[0;34m,\u001b[0m \u001b[0moutput_file\u001b[0m\u001b[0;34m,\u001b[0m \u001b[0mW\u001b[0m\u001b[0;34m,\u001b[0m \u001b[0mH\u001b[0m\u001b[0;34m,\u001b[0m \u001b[0mguidance_scale\u001b[0m\u001b[0;34m,\u001b[0m \u001b[0mguidance_rescale\u001b[0m\u001b[0;34m,\u001b[0m \u001b[0mnum_inference_steps\u001b[0m\u001b[0;34m,\u001b[0m \u001b[0mset_seed\u001b[0m\u001b[0;34m)\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[0m\u001b[1;32m     93\u001b[0m     \u001b[0mblurred_image\u001b[0m \u001b[0;34m=\u001b[0m \u001b[0mimage\u001b[0m\u001b[0;34m.\u001b[0m\u001b[0mfilter\u001b[0m\u001b[0;34m(\u001b[0m\u001b[0mImageFilter\u001b[0m\u001b[0;34m.\u001b[0m\u001b[0mGaussianBlur\u001b[0m\u001b[0;34m(\u001b[0m\u001b[0mradius\u001b[0m\u001b[0;34m=\u001b[0m\u001b[0;36m15\u001b[0m\u001b[0;34m)\u001b[0m\u001b[0;34m)\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[1;32m     94\u001b[0m     \u001b[0mplt\u001b[0m\u001b[0;34m.\u001b[0m\u001b[0mfigure\u001b[0m\u001b[0;34m(\u001b[0m\u001b[0mfigsize\u001b[0m\u001b[0;34m=\u001b[0m\u001b[0;34m(\u001b[0m\u001b[0mW\u001b[0m\u001b[0;34m/\u001b[0m\u001b[0;36m80\u001b[0m\u001b[0;34m,\u001b[0m \u001b[0mH\u001b[0m\u001b[0;34m/\u001b[0m\u001b[0;36m80\u001b[0m\u001b[0;34m)\u001b[0m\u001b[0;34m)\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n",
            "\u001b[0;32m<ipython-input-86-7cda760ae67e>\u001b[0m in \u001b[0;36mgenerate_image\u001b[0;34m(pipe, prompt, negative_prompt, output_path, width, height, guidance_scale, guidance_rescale, num_inference_steps, seed)\u001b[0m\n\u001b[1;32m      5\u001b[0m \u001b[0;32mdef\u001b[0m \u001b[0mgenerate_image\u001b[0m\u001b[0;34m(\u001b[0m\u001b[0mpipe\u001b[0m\u001b[0;34m,\u001b[0m \u001b[0mprompt\u001b[0m\u001b[0;34m,\u001b[0m \u001b[0mnegative_prompt\u001b[0m\u001b[0;34m,\u001b[0m \u001b[0moutput_path\u001b[0m\u001b[0;34m,\u001b[0m \u001b[0mwidth\u001b[0m\u001b[0;34m,\u001b[0m \u001b[0mheight\u001b[0m\u001b[0;34m,\u001b[0m \u001b[0mguidance_scale\u001b[0m\u001b[0;34m,\u001b[0m \u001b[0mguidance_rescale\u001b[0m\u001b[0;34m,\u001b[0m \u001b[0mnum_inference_steps\u001b[0m\u001b[0;34m,\u001b[0m \u001b[0mseed\u001b[0m\u001b[0;34m)\u001b[0m\u001b[0;34m:\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[1;32m      6\u001b[0m     \u001b[0;34m\"\"\"Menghasilkan gambar Stable Diffusion.\"\"\"\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[0;32m----> 7\u001b[0;31m     image = pipe(\n\u001b[0m\u001b[1;32m      8\u001b[0m         \u001b[0mprompt\u001b[0m\u001b[0;34m=\u001b[0m\u001b[0mprompt\u001b[0m\u001b[0;34m,\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[1;32m      9\u001b[0m         \u001b[0mnegative_prompt\u001b[0m\u001b[0;34m=\u001b[0m\u001b[0mnegative_prompt\u001b[0m\u001b[0;34m,\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n",
            "\u001b[0;32m/usr/local/lib/python3.11/dist-packages/torch/utils/_contextlib.py\u001b[0m in \u001b[0;36mdecorate_context\u001b[0;34m(*args, **kwargs)\u001b[0m\n\u001b[1;32m    114\u001b[0m     \u001b[0;32mdef\u001b[0m \u001b[0mdecorate_context\u001b[0m\u001b[0;34m(\u001b[0m\u001b[0;34m*\u001b[0m\u001b[0margs\u001b[0m\u001b[0;34m,\u001b[0m \u001b[0;34m**\u001b[0m\u001b[0mkwargs\u001b[0m\u001b[0;34m)\u001b[0m\u001b[0;34m:\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[1;32m    115\u001b[0m         \u001b[0;32mwith\u001b[0m \u001b[0mctx_factory\u001b[0m\u001b[0;34m(\u001b[0m\u001b[0;34m)\u001b[0m\u001b[0;34m:\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[0;32m--> 116\u001b[0;31m             \u001b[0;32mreturn\u001b[0m \u001b[0mfunc\u001b[0m\u001b[0;34m(\u001b[0m\u001b[0;34m*\u001b[0m\u001b[0margs\u001b[0m\u001b[0;34m,\u001b[0m \u001b[0;34m**\u001b[0m\u001b[0mkwargs\u001b[0m\u001b[0;34m)\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[0m\u001b[1;32m    117\u001b[0m \u001b[0;34m\u001b[0m\u001b[0m\n\u001b[1;32m    118\u001b[0m     \u001b[0;32mreturn\u001b[0m \u001b[0mdecorate_context\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n",
            "\u001b[0;32m~/.cache/huggingface/modules/diffusers_modules/git/lpw_stable_diffusion_xl.py\u001b[0m in \u001b[0;36m__call__\u001b[0;34m(self, prompt, prompt_2, image, mask_image, masked_image_latents, height, width, strength, num_inference_steps, timesteps, denoising_start, denoising_end, guidance_scale, negative_prompt, negative_prompt_2, num_images_per_prompt, eta, generator, latents, ip_adapter_image, prompt_embeds, negative_prompt_embeds, pooled_prompt_embeds, negative_pooled_prompt_embeds, output_type, return_dict, cross_attention_kwargs, guidance_rescale, original_size, crops_coords_top_left, target_size, clip_skip, callback_on_step_end, callback_on_step_end_tensor_inputs, **kwargs)\u001b[0m\n\u001b[1;32m   1857\u001b[0m                 \u001b[0;31m# predict the noise residual\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[1;32m   1858\u001b[0m                 \u001b[0madded_cond_kwargs\u001b[0m\u001b[0;34m.\u001b[0m\u001b[0mupdate\u001b[0m\u001b[0;34m(\u001b[0m\u001b[0;34m{\u001b[0m\u001b[0;34m\"text_embeds\"\u001b[0m\u001b[0;34m:\u001b[0m \u001b[0madd_text_embeds\u001b[0m\u001b[0;34m,\u001b[0m \u001b[0;34m\"time_ids\"\u001b[0m\u001b[0;34m:\u001b[0m \u001b[0madd_time_ids\u001b[0m\u001b[0;34m}\u001b[0m\u001b[0;34m)\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[0;32m-> 1859\u001b[0;31m                 noise_pred = self.unet(\n\u001b[0m\u001b[1;32m   1860\u001b[0m                     \u001b[0mlatent_model_input\u001b[0m\u001b[0;34m,\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[1;32m   1861\u001b[0m                     \u001b[0mt\u001b[0m\u001b[0;34m,\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n",
            "\u001b[0;32m/usr/local/lib/python3.11/dist-packages/torch/nn/modules/module.py\u001b[0m in \u001b[0;36m_wrapped_call_impl\u001b[0;34m(self, *args, **kwargs)\u001b[0m\n\u001b[1;32m   1737\u001b[0m             \u001b[0;32mreturn\u001b[0m \u001b[0mself\u001b[0m\u001b[0;34m.\u001b[0m\u001b[0m_compiled_call_impl\u001b[0m\u001b[0;34m(\u001b[0m\u001b[0;34m*\u001b[0m\u001b[0margs\u001b[0m\u001b[0;34m,\u001b[0m \u001b[0;34m**\u001b[0m\u001b[0mkwargs\u001b[0m\u001b[0;34m)\u001b[0m  \u001b[0;31m# type: ignore[misc]\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[1;32m   1738\u001b[0m         \u001b[0;32melse\u001b[0m\u001b[0;34m:\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[0;32m-> 1739\u001b[0;31m             \u001b[0;32mreturn\u001b[0m \u001b[0mself\u001b[0m\u001b[0;34m.\u001b[0m\u001b[0m_call_impl\u001b[0m\u001b[0;34m(\u001b[0m\u001b[0;34m*\u001b[0m\u001b[0margs\u001b[0m\u001b[0;34m,\u001b[0m \u001b[0;34m**\u001b[0m\u001b[0mkwargs\u001b[0m\u001b[0;34m)\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[0m\u001b[1;32m   1740\u001b[0m \u001b[0;34m\u001b[0m\u001b[0m\n\u001b[1;32m   1741\u001b[0m     \u001b[0;31m# torchrec tests the code consistency with the following code\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n",
            "\u001b[0;32m/usr/local/lib/python3.11/dist-packages/torch/nn/modules/module.py\u001b[0m in \u001b[0;36m_call_impl\u001b[0;34m(self, *args, **kwargs)\u001b[0m\n\u001b[1;32m   1748\u001b[0m                 \u001b[0;32mor\u001b[0m \u001b[0m_global_backward_pre_hooks\u001b[0m \u001b[0;32mor\u001b[0m \u001b[0m_global_backward_hooks\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[1;32m   1749\u001b[0m                 or _global_forward_hooks or _global_forward_pre_hooks):\n\u001b[0;32m-> 1750\u001b[0;31m             \u001b[0;32mreturn\u001b[0m \u001b[0mforward_call\u001b[0m\u001b[0;34m(\u001b[0m\u001b[0;34m*\u001b[0m\u001b[0margs\u001b[0m\u001b[0;34m,\u001b[0m \u001b[0;34m**\u001b[0m\u001b[0mkwargs\u001b[0m\u001b[0;34m)\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[0m\u001b[1;32m   1751\u001b[0m \u001b[0;34m\u001b[0m\u001b[0m\n\u001b[1;32m   1752\u001b[0m         \u001b[0mresult\u001b[0m \u001b[0;34m=\u001b[0m \u001b[0;32mNone\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n",
            "\u001b[0;32m/usr/local/lib/python3.11/dist-packages/diffusers/models/unets/unet_2d_condition.py\u001b[0m in \u001b[0;36mforward\u001b[0;34m(self, sample, timestep, encoder_hidden_states, class_labels, timestep_cond, attention_mask, cross_attention_kwargs, added_cond_kwargs, down_block_additional_residuals, mid_block_additional_residual, down_intrablock_additional_residuals, encoder_attention_mask, return_dict)\u001b[0m\n\u001b[1;32m   1277\u001b[0m \u001b[0;34m\u001b[0m\u001b[0m\n\u001b[1;32m   1278\u001b[0m             \u001b[0;32mif\u001b[0m \u001b[0mhasattr\u001b[0m\u001b[0;34m(\u001b[0m\u001b[0mupsample_block\u001b[0m\u001b[0;34m,\u001b[0m \u001b[0;34m\"has_cross_attention\"\u001b[0m\u001b[0;34m)\u001b[0m \u001b[0;32mand\u001b[0m \u001b[0mupsample_block\u001b[0m\u001b[0;34m.\u001b[0m\u001b[0mhas_cross_attention\u001b[0m\u001b[0;34m:\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[0;32m-> 1279\u001b[0;31m                 sample = upsample_block(\n\u001b[0m\u001b[1;32m   1280\u001b[0m                     \u001b[0mhidden_states\u001b[0m\u001b[0;34m=\u001b[0m\u001b[0msample\u001b[0m\u001b[0;34m,\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[1;32m   1281\u001b[0m                     \u001b[0mtemb\u001b[0m\u001b[0;34m=\u001b[0m\u001b[0memb\u001b[0m\u001b[0;34m,\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n",
            "\u001b[0;32m/usr/local/lib/python3.11/dist-packages/torch/nn/modules/module.py\u001b[0m in \u001b[0;36m_wrapped_call_impl\u001b[0;34m(self, *args, **kwargs)\u001b[0m\n\u001b[1;32m   1737\u001b[0m             \u001b[0;32mreturn\u001b[0m \u001b[0mself\u001b[0m\u001b[0;34m.\u001b[0m\u001b[0m_compiled_call_impl\u001b[0m\u001b[0;34m(\u001b[0m\u001b[0;34m*\u001b[0m\u001b[0margs\u001b[0m\u001b[0;34m,\u001b[0m \u001b[0;34m**\u001b[0m\u001b[0mkwargs\u001b[0m\u001b[0;34m)\u001b[0m  \u001b[0;31m# type: ignore[misc]\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[1;32m   1738\u001b[0m         \u001b[0;32melse\u001b[0m\u001b[0;34m:\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[0;32m-> 1739\u001b[0;31m             \u001b[0;32mreturn\u001b[0m \u001b[0mself\u001b[0m\u001b[0;34m.\u001b[0m\u001b[0m_call_impl\u001b[0m\u001b[0;34m(\u001b[0m\u001b[0;34m*\u001b[0m\u001b[0margs\u001b[0m\u001b[0;34m,\u001b[0m \u001b[0;34m**\u001b[0m\u001b[0mkwargs\u001b[0m\u001b[0;34m)\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[0m\u001b[1;32m   1740\u001b[0m \u001b[0;34m\u001b[0m\u001b[0m\n\u001b[1;32m   1741\u001b[0m     \u001b[0;31m# torchrec tests the code consistency with the following code\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n",
            "\u001b[0;32m/usr/local/lib/python3.11/dist-packages/torch/nn/modules/module.py\u001b[0m in \u001b[0;36m_call_impl\u001b[0;34m(self, *args, **kwargs)\u001b[0m\n\u001b[1;32m   1748\u001b[0m                 \u001b[0;32mor\u001b[0m \u001b[0m_global_backward_pre_hooks\u001b[0m \u001b[0;32mor\u001b[0m \u001b[0m_global_backward_hooks\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[1;32m   1749\u001b[0m                 or _global_forward_hooks or _global_forward_pre_hooks):\n\u001b[0;32m-> 1750\u001b[0;31m             \u001b[0;32mreturn\u001b[0m \u001b[0mforward_call\u001b[0m\u001b[0;34m(\u001b[0m\u001b[0;34m*\u001b[0m\u001b[0margs\u001b[0m\u001b[0;34m,\u001b[0m \u001b[0;34m**\u001b[0m\u001b[0mkwargs\u001b[0m\u001b[0;34m)\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[0m\u001b[1;32m   1751\u001b[0m \u001b[0;34m\u001b[0m\u001b[0m\n\u001b[1;32m   1752\u001b[0m         \u001b[0mresult\u001b[0m \u001b[0;34m=\u001b[0m \u001b[0;32mNone\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n",
            "\u001b[0;32m/usr/local/lib/python3.11/dist-packages/diffusers/models/unets/unet_2d_blocks.py\u001b[0m in \u001b[0;36mforward\u001b[0;34m(self, hidden_states, res_hidden_states_tuple, temb, encoder_hidden_states, cross_attention_kwargs, upsample_size, attention_mask, encoder_attention_mask)\u001b[0m\n\u001b[1;32m   2456\u001b[0m             \u001b[0;32melse\u001b[0m\u001b[0;34m:\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[1;32m   2457\u001b[0m                 \u001b[0mhidden_states\u001b[0m \u001b[0;34m=\u001b[0m \u001b[0mresnet\u001b[0m\u001b[0;34m(\u001b[0m\u001b[0mhidden_states\u001b[0m\u001b[0;34m,\u001b[0m \u001b[0mtemb\u001b[0m\u001b[0;34m)\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[0;32m-> 2458\u001b[0;31m                 hidden_states = attn(\n\u001b[0m\u001b[1;32m   2459\u001b[0m                     \u001b[0mhidden_states\u001b[0m\u001b[0;34m,\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[1;32m   2460\u001b[0m                     \u001b[0mencoder_hidden_states\u001b[0m\u001b[0;34m=\u001b[0m\u001b[0mencoder_hidden_states\u001b[0m\u001b[0;34m,\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n",
            "\u001b[0;32m/usr/local/lib/python3.11/dist-packages/torch/nn/modules/module.py\u001b[0m in \u001b[0;36m_wrapped_call_impl\u001b[0;34m(self, *args, **kwargs)\u001b[0m\n\u001b[1;32m   1737\u001b[0m             \u001b[0;32mreturn\u001b[0m \u001b[0mself\u001b[0m\u001b[0;34m.\u001b[0m\u001b[0m_compiled_call_impl\u001b[0m\u001b[0;34m(\u001b[0m\u001b[0;34m*\u001b[0m\u001b[0margs\u001b[0m\u001b[0;34m,\u001b[0m \u001b[0;34m**\u001b[0m\u001b[0mkwargs\u001b[0m\u001b[0;34m)\u001b[0m  \u001b[0;31m# type: ignore[misc]\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[1;32m   1738\u001b[0m         \u001b[0;32melse\u001b[0m\u001b[0;34m:\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[0;32m-> 1739\u001b[0;31m             \u001b[0;32mreturn\u001b[0m \u001b[0mself\u001b[0m\u001b[0;34m.\u001b[0m\u001b[0m_call_impl\u001b[0m\u001b[0;34m(\u001b[0m\u001b[0;34m*\u001b[0m\u001b[0margs\u001b[0m\u001b[0;34m,\u001b[0m \u001b[0;34m**\u001b[0m\u001b[0mkwargs\u001b[0m\u001b[0;34m)\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[0m\u001b[1;32m   1740\u001b[0m \u001b[0;34m\u001b[0m\u001b[0m\n\u001b[1;32m   1741\u001b[0m     \u001b[0;31m# torchrec tests the code consistency with the following code\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n",
            "\u001b[0;32m/usr/local/lib/python3.11/dist-packages/torch/nn/modules/module.py\u001b[0m in \u001b[0;36m_call_impl\u001b[0;34m(self, *args, **kwargs)\u001b[0m\n\u001b[1;32m   1748\u001b[0m                 \u001b[0;32mor\u001b[0m \u001b[0m_global_backward_pre_hooks\u001b[0m \u001b[0;32mor\u001b[0m \u001b[0m_global_backward_hooks\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[1;32m   1749\u001b[0m                 or _global_forward_hooks or _global_forward_pre_hooks):\n\u001b[0;32m-> 1750\u001b[0;31m             \u001b[0;32mreturn\u001b[0m \u001b[0mforward_call\u001b[0m\u001b[0;34m(\u001b[0m\u001b[0;34m*\u001b[0m\u001b[0margs\u001b[0m\u001b[0;34m,\u001b[0m \u001b[0;34m**\u001b[0m\u001b[0mkwargs\u001b[0m\u001b[0;34m)\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[0m\u001b[1;32m   1751\u001b[0m \u001b[0;34m\u001b[0m\u001b[0m\n\u001b[1;32m   1752\u001b[0m         \u001b[0mresult\u001b[0m \u001b[0;34m=\u001b[0m \u001b[0;32mNone\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n",
            "\u001b[0;32m/usr/local/lib/python3.11/dist-packages/diffusers/models/transformers/transformer_2d.py\u001b[0m in \u001b[0;36mforward\u001b[0;34m(self, hidden_states, encoder_hidden_states, timestep, added_cond_kwargs, class_labels, cross_attention_kwargs, attention_mask, encoder_attention_mask, return_dict)\u001b[0m\n\u001b[1;32m    425\u001b[0m                 )\n\u001b[1;32m    426\u001b[0m             \u001b[0;32melse\u001b[0m\u001b[0;34m:\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[0;32m--> 427\u001b[0;31m                 hidden_states = block(\n\u001b[0m\u001b[1;32m    428\u001b[0m                     \u001b[0mhidden_states\u001b[0m\u001b[0;34m,\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[1;32m    429\u001b[0m                     \u001b[0mattention_mask\u001b[0m\u001b[0;34m=\u001b[0m\u001b[0mattention_mask\u001b[0m\u001b[0;34m,\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n",
            "\u001b[0;32m/usr/local/lib/python3.11/dist-packages/torch/nn/modules/module.py\u001b[0m in \u001b[0;36m_wrapped_call_impl\u001b[0;34m(self, *args, **kwargs)\u001b[0m\n\u001b[1;32m   1737\u001b[0m             \u001b[0;32mreturn\u001b[0m \u001b[0mself\u001b[0m\u001b[0;34m.\u001b[0m\u001b[0m_compiled_call_impl\u001b[0m\u001b[0;34m(\u001b[0m\u001b[0;34m*\u001b[0m\u001b[0margs\u001b[0m\u001b[0;34m,\u001b[0m \u001b[0;34m**\u001b[0m\u001b[0mkwargs\u001b[0m\u001b[0;34m)\u001b[0m  \u001b[0;31m# type: ignore[misc]\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[1;32m   1738\u001b[0m         \u001b[0;32melse\u001b[0m\u001b[0;34m:\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[0;32m-> 1739\u001b[0;31m             \u001b[0;32mreturn\u001b[0m \u001b[0mself\u001b[0m\u001b[0;34m.\u001b[0m\u001b[0m_call_impl\u001b[0m\u001b[0;34m(\u001b[0m\u001b[0;34m*\u001b[0m\u001b[0margs\u001b[0m\u001b[0;34m,\u001b[0m \u001b[0;34m**\u001b[0m\u001b[0mkwargs\u001b[0m\u001b[0;34m)\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[0m\u001b[1;32m   1740\u001b[0m \u001b[0;34m\u001b[0m\u001b[0m\n\u001b[1;32m   1741\u001b[0m     \u001b[0;31m# torchrec tests the code consistency with the following code\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n",
            "\u001b[0;32m/usr/local/lib/python3.11/dist-packages/torch/nn/modules/module.py\u001b[0m in \u001b[0;36m_call_impl\u001b[0;34m(self, *args, **kwargs)\u001b[0m\n\u001b[1;32m   1748\u001b[0m                 \u001b[0;32mor\u001b[0m \u001b[0m_global_backward_pre_hooks\u001b[0m \u001b[0;32mor\u001b[0m \u001b[0m_global_backward_hooks\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[1;32m   1749\u001b[0m                 or _global_forward_hooks or _global_forward_pre_hooks):\n\u001b[0;32m-> 1750\u001b[0;31m             \u001b[0;32mreturn\u001b[0m \u001b[0mforward_call\u001b[0m\u001b[0;34m(\u001b[0m\u001b[0;34m*\u001b[0m\u001b[0margs\u001b[0m\u001b[0;34m,\u001b[0m \u001b[0;34m**\u001b[0m\u001b[0mkwargs\u001b[0m\u001b[0;34m)\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[0m\u001b[1;32m   1751\u001b[0m \u001b[0;34m\u001b[0m\u001b[0m\n\u001b[1;32m   1752\u001b[0m         \u001b[0mresult\u001b[0m \u001b[0;34m=\u001b[0m \u001b[0;32mNone\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n",
            "\u001b[0;32m/usr/local/lib/python3.11/dist-packages/diffusers/models/attention.py\u001b[0m in \u001b[0;36mforward\u001b[0;34m(self, hidden_states, attention_mask, encoder_hidden_states, encoder_attention_mask, timestep, cross_attention_kwargs, class_labels, added_cond_kwargs)\u001b[0m\n\u001b[1;32m    576\u001b[0m             \u001b[0mff_output\u001b[0m \u001b[0;34m=\u001b[0m \u001b[0m_chunked_feed_forward\u001b[0m\u001b[0;34m(\u001b[0m\u001b[0mself\u001b[0m\u001b[0;34m.\u001b[0m\u001b[0mff\u001b[0m\u001b[0;34m,\u001b[0m \u001b[0mnorm_hidden_states\u001b[0m\u001b[0;34m,\u001b[0m \u001b[0mself\u001b[0m\u001b[0;34m.\u001b[0m\u001b[0m_chunk_dim\u001b[0m\u001b[0;34m,\u001b[0m \u001b[0mself\u001b[0m\u001b[0;34m.\u001b[0m\u001b[0m_chunk_size\u001b[0m\u001b[0;34m)\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[1;32m    577\u001b[0m         \u001b[0;32melse\u001b[0m\u001b[0;34m:\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[0;32m--> 578\u001b[0;31m             \u001b[0mff_output\u001b[0m \u001b[0;34m=\u001b[0m \u001b[0mself\u001b[0m\u001b[0;34m.\u001b[0m\u001b[0mff\u001b[0m\u001b[0;34m(\u001b[0m\u001b[0mnorm_hidden_states\u001b[0m\u001b[0;34m)\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[0m\u001b[1;32m    579\u001b[0m \u001b[0;34m\u001b[0m\u001b[0m\n\u001b[1;32m    580\u001b[0m         \u001b[0;32mif\u001b[0m \u001b[0mself\u001b[0m\u001b[0;34m.\u001b[0m\u001b[0mnorm_type\u001b[0m \u001b[0;34m==\u001b[0m \u001b[0;34m\"ada_norm_zero\"\u001b[0m\u001b[0;34m:\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n",
            "\u001b[0;32m/usr/local/lib/python3.11/dist-packages/torch/nn/modules/module.py\u001b[0m in \u001b[0;36m_wrapped_call_impl\u001b[0;34m(self, *args, **kwargs)\u001b[0m\n\u001b[1;32m   1737\u001b[0m             \u001b[0;32mreturn\u001b[0m \u001b[0mself\u001b[0m\u001b[0;34m.\u001b[0m\u001b[0m_compiled_call_impl\u001b[0m\u001b[0;34m(\u001b[0m\u001b[0;34m*\u001b[0m\u001b[0margs\u001b[0m\u001b[0;34m,\u001b[0m \u001b[0;34m**\u001b[0m\u001b[0mkwargs\u001b[0m\u001b[0;34m)\u001b[0m  \u001b[0;31m# type: ignore[misc]\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[1;32m   1738\u001b[0m         \u001b[0;32melse\u001b[0m\u001b[0;34m:\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[0;32m-> 1739\u001b[0;31m             \u001b[0;32mreturn\u001b[0m \u001b[0mself\u001b[0m\u001b[0;34m.\u001b[0m\u001b[0m_call_impl\u001b[0m\u001b[0;34m(\u001b[0m\u001b[0;34m*\u001b[0m\u001b[0margs\u001b[0m\u001b[0;34m,\u001b[0m \u001b[0;34m**\u001b[0m\u001b[0mkwargs\u001b[0m\u001b[0;34m)\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[0m\u001b[1;32m   1740\u001b[0m \u001b[0;34m\u001b[0m\u001b[0m\n\u001b[1;32m   1741\u001b[0m     \u001b[0;31m# torchrec tests the code consistency with the following code\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n",
            "\u001b[0;32m/usr/local/lib/python3.11/dist-packages/torch/nn/modules/module.py\u001b[0m in \u001b[0;36m_call_impl\u001b[0;34m(self, *args, **kwargs)\u001b[0m\n\u001b[1;32m   1748\u001b[0m                 \u001b[0;32mor\u001b[0m \u001b[0m_global_backward_pre_hooks\u001b[0m \u001b[0;32mor\u001b[0m \u001b[0m_global_backward_hooks\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[1;32m   1749\u001b[0m                 or _global_forward_hooks or _global_forward_pre_hooks):\n\u001b[0;32m-> 1750\u001b[0;31m             \u001b[0;32mreturn\u001b[0m \u001b[0mforward_call\u001b[0m\u001b[0;34m(\u001b[0m\u001b[0;34m*\u001b[0m\u001b[0margs\u001b[0m\u001b[0;34m,\u001b[0m \u001b[0;34m**\u001b[0m\u001b[0mkwargs\u001b[0m\u001b[0;34m)\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[0m\u001b[1;32m   1751\u001b[0m \u001b[0;34m\u001b[0m\u001b[0m\n\u001b[1;32m   1752\u001b[0m         \u001b[0mresult\u001b[0m \u001b[0;34m=\u001b[0m \u001b[0;32mNone\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n",
            "\u001b[0;32m/usr/local/lib/python3.11/dist-packages/diffusers/models/attention.py\u001b[0m in \u001b[0;36mforward\u001b[0;34m(self, hidden_states, *args, **kwargs)\u001b[0m\n\u001b[1;32m   1248\u001b[0m             \u001b[0mdeprecate\u001b[0m\u001b[0;34m(\u001b[0m\u001b[0;34m\"scale\"\u001b[0m\u001b[0;34m,\u001b[0m \u001b[0;34m\"1.0.0\"\u001b[0m\u001b[0;34m,\u001b[0m \u001b[0mdeprecation_message\u001b[0m\u001b[0;34m)\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[1;32m   1249\u001b[0m         \u001b[0;32mfor\u001b[0m \u001b[0mmodule\u001b[0m \u001b[0;32min\u001b[0m \u001b[0mself\u001b[0m\u001b[0;34m.\u001b[0m\u001b[0mnet\u001b[0m\u001b[0;34m:\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[0;32m-> 1250\u001b[0;31m             \u001b[0mhidden_states\u001b[0m \u001b[0;34m=\u001b[0m \u001b[0mmodule\u001b[0m\u001b[0;34m(\u001b[0m\u001b[0mhidden_states\u001b[0m\u001b[0;34m)\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[0m\u001b[1;32m   1251\u001b[0m         \u001b[0;32mreturn\u001b[0m \u001b[0mhidden_states\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n",
            "\u001b[0;32m/usr/local/lib/python3.11/dist-packages/torch/nn/modules/module.py\u001b[0m in \u001b[0;36m_wrapped_call_impl\u001b[0;34m(self, *args, **kwargs)\u001b[0m\n\u001b[1;32m   1737\u001b[0m             \u001b[0;32mreturn\u001b[0m \u001b[0mself\u001b[0m\u001b[0;34m.\u001b[0m\u001b[0m_compiled_call_impl\u001b[0m\u001b[0;34m(\u001b[0m\u001b[0;34m*\u001b[0m\u001b[0margs\u001b[0m\u001b[0;34m,\u001b[0m \u001b[0;34m**\u001b[0m\u001b[0mkwargs\u001b[0m\u001b[0;34m)\u001b[0m  \u001b[0;31m# type: ignore[misc]\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[1;32m   1738\u001b[0m         \u001b[0;32melse\u001b[0m\u001b[0;34m:\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[0;32m-> 1739\u001b[0;31m             \u001b[0;32mreturn\u001b[0m \u001b[0mself\u001b[0m\u001b[0;34m.\u001b[0m\u001b[0m_call_impl\u001b[0m\u001b[0;34m(\u001b[0m\u001b[0;34m*\u001b[0m\u001b[0margs\u001b[0m\u001b[0;34m,\u001b[0m \u001b[0;34m**\u001b[0m\u001b[0mkwargs\u001b[0m\u001b[0;34m)\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[0m\u001b[1;32m   1740\u001b[0m \u001b[0;34m\u001b[0m\u001b[0m\n\u001b[1;32m   1741\u001b[0m     \u001b[0;31m# torchrec tests the code consistency with the following code\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n",
            "\u001b[0;32m/usr/local/lib/python3.11/dist-packages/torch/nn/modules/module.py\u001b[0m in \u001b[0;36m_call_impl\u001b[0;34m(self, *args, **kwargs)\u001b[0m\n\u001b[1;32m   1748\u001b[0m                 \u001b[0;32mor\u001b[0m \u001b[0m_global_backward_pre_hooks\u001b[0m \u001b[0;32mor\u001b[0m \u001b[0m_global_backward_hooks\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[1;32m   1749\u001b[0m                 or _global_forward_hooks or _global_forward_pre_hooks):\n\u001b[0;32m-> 1750\u001b[0;31m             \u001b[0;32mreturn\u001b[0m \u001b[0mforward_call\u001b[0m\u001b[0;34m(\u001b[0m\u001b[0;34m*\u001b[0m\u001b[0margs\u001b[0m\u001b[0;34m,\u001b[0m \u001b[0;34m**\u001b[0m\u001b[0mkwargs\u001b[0m\u001b[0;34m)\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[0m\u001b[1;32m   1751\u001b[0m \u001b[0;34m\u001b[0m\u001b[0m\n\u001b[1;32m   1752\u001b[0m         \u001b[0mresult\u001b[0m \u001b[0;34m=\u001b[0m \u001b[0;32mNone\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n",
            "\u001b[0;32m/usr/local/lib/python3.11/dist-packages/diffusers/models/activations.py\u001b[0m in \u001b[0;36mforward\u001b[0;34m(self, hidden_states, *args, **kwargs)\u001b[0m\n\u001b[1;32m    121\u001b[0m         \u001b[0;32melse\u001b[0m\u001b[0;34m:\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[1;32m    122\u001b[0m             \u001b[0mhidden_states\u001b[0m\u001b[0;34m,\u001b[0m \u001b[0mgate\u001b[0m \u001b[0;34m=\u001b[0m \u001b[0mhidden_states\u001b[0m\u001b[0;34m.\u001b[0m\u001b[0mchunk\u001b[0m\u001b[0;34m(\u001b[0m\u001b[0;36m2\u001b[0m\u001b[0;34m,\u001b[0m \u001b[0mdim\u001b[0m\u001b[0;34m=\u001b[0m\u001b[0;34m-\u001b[0m\u001b[0;36m1\u001b[0m\u001b[0;34m)\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[0;32m--> 123\u001b[0;31m             \u001b[0;32mreturn\u001b[0m \u001b[0mhidden_states\u001b[0m \u001b[0;34m*\u001b[0m \u001b[0mself\u001b[0m\u001b[0;34m.\u001b[0m\u001b[0mgelu\u001b[0m\u001b[0;34m(\u001b[0m\u001b[0mgate\u001b[0m\u001b[0;34m)\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[0m\u001b[1;32m    124\u001b[0m \u001b[0;34m\u001b[0m\u001b[0m\n\u001b[1;32m    125\u001b[0m \u001b[0;34m\u001b[0m\u001b[0m\n",
            "\u001b[0;31mOutOfMemoryError\u001b[0m: CUDA out of memory. Tried to allocate 50.00 MiB. GPU 0 has a total capacity of 14.74 GiB of which 50.12 MiB is free. Process 2367 has 14.69 GiB memory in use. Of the allocated memory 14.04 GiB is allocated by PyTorch, and 534.33 MiB is reserved by PyTorch but unallocated. If reserved but unallocated memory is large try setting PYTORCH_CUDA_ALLOC_CONF=expandable_segments:True to avoid fragmentation.  See documentation for Memory Management  (https://pytorch.org/docs/stable/notes/cuda.html#environment-variables)"
          ]
        }
      ]
    },
    {
      "cell_type": "code",
      "source": [
        "#@title +load_lora\n",
        "from google.colab import drive\n",
        "import datetime\n",
        "# drive.mount('/content/drive')\n",
        "\n",
        "lora_path = \"/content/drive/MyDrive/Colab Notebooks/parsley-XL-v31-ep20.safetensors\" #@param {type:\"string\"}\n",
        "print(f\"Memasang LoRA dari: {lora_path}\")\n",
        "pipe.load_lora_weights(lora_path)"
      ],
      "metadata": {
        "id": "O7qLIXKRlUGe",
        "outputId": "70628dd7-b43a-4596-9dd4-23505940cb6b",
        "colab": {
          "base_uri": "https://localhost:8080/"
        }
      },
      "execution_count": 71,
      "outputs": [
        {
          "output_type": "stream",
          "name": "stdout",
          "text": [
            "Memasang LoRA dari: /content/drive/MyDrive/Colab Notebooks/parsley-XL-v31-ep20.safetensors\n"
          ]
        }
      ]
    },
    {
      "cell_type": "code",
      "source": [
        "#@title +unload_lora\n",
        "\n",
        "print(\"Melepas LoRA\")\n",
        "pipe.unload_lora_weights()"
      ],
      "metadata": {
        "id": "k3HAgwYMB7RN",
        "outputId": "00cf1feb-1026-4f0f-cd6b-fd584f98a91a",
        "colab": {
          "base_uri": "https://localhost:8080/"
        }
      },
      "execution_count": 70,
      "outputs": [
        {
          "output_type": "stream",
          "name": "stdout",
          "text": [
            "Melepas LoRA\n"
          ]
        }
      ]
    },
    {
      "cell_type": "code",
      "source": [
        "#@title ##**Tagger**\n",
        "#!git clone https://github.com/neggles/wdv3-timm.git\n",
        "#!pip install -q -r \"/content/wdv3-timm/requirements.txt\"\n",
        "!curl -o wd14-tagger.py https://raw.githubusercontent.com/FreNzQuiN/GenerativeAI/refs/heads/main/Stable_Diffusion/wd14-tagger.py\n"
      ],
      "metadata": {
        "id": "25mGDN6ksl-M"
      },
      "execution_count": null,
      "outputs": []
    },
    {
      "cell_type": "code",
      "source": [
        "# Run\n",
        "# <swinv2|convnext|vit>\n",
        "path = \"/content/outputs/goldenglow_sensitive/anime_1girl_14_793090893_sensitive safe.png\" # @param [] {\"allow-input\":true}\n",
        "#!python /content/wdv3-timm/wdv3_timm.py <swinv2|convnext|vit> {path}\n",
        "!python /content/wd14-tagger.py \"{path}\""
      ],
      "metadata": {
        "id": "D7w69wWd1gZ5",
        "outputId": "3f169025-a254-40d1-dcfc-9660ba6f9413",
        "colab": {
          "base_uri": "https://localhost:8080/"
        }
      },
      "execution_count": 24,
      "outputs": [
        {
          "output_type": "stream",
          "name": "stdout",
          "text": [
            "Traceback (most recent call last):\n",
            "  File \"/content/wd14-tagger.py\", line 203, in <module>\n",
            "    main(opts)\n",
            "  File \"/content/wd14-tagger.py\", line 126, in main\n",
            "    raise FileNotFoundError(f\"Image file not found: {image_path}\")\n",
            "FileNotFoundError: Image file not found: /content/outputs/goldenglow_sensitive/anime_1girl_14_793090893_sensitive\n"
          ]
        }
      ]
    },
    {
      "cell_type": "code",
      "source": [
        "#@title ##**2.2 PLAY IMG2IMG**\n",
        "def image_grid(imgs, rows, cols):\n",
        "    assert len(imgs) == rows * cols\n",
        "\n",
        "    w, h = imgs[0].size\n",
        "    grid = Image.new('RGB', size=(cols * w, rows * h))\n",
        "    grid_w, grid_h = grid.size\n",
        "\n",
        "    for i, img in enumerate(imgs):\n",
        "        grid.paste(img, box=(i % cols * w, i // cols * h))\n",
        "    return grid\n",
        "\n",
        "def download_image(url):\n",
        "    response = requests.get(url)\n",
        "    return Image.open(BytesIO(response.content)).convert(\"RGB\")\n",
        "\n",
        "def img2img_generation(image, prompt, negative_prompt, num_inference_steps=25, guidance_scale=7.5, strength=0.7):\n",
        "    images = pipe(\n",
        "        prompt=prompt,\n",
        "        negative_prompt=negative_prompt,\n",
        "        image=image,\n",
        "        num_inference_steps=num_inference_steps,\n",
        "        guidance_scale=guidance_scale,\n",
        "        strength=strength,\n",
        "    ).images\n",
        "    return images\n",
        "\n",
        "# Contoh Penggunaan img2img\n",
        "image_url = \"https://huggingface.co/datasets/hf-internal-testing/diffusers-images/resolve/main/sd_xl/input_1024x1024.png\"\n",
        "init_image = download_image(image_url)\n",
        "\n",
        "prompt = \"A futuristic city skyline, neon lights, cyberpunk style\"\n",
        "negative_prompt = \"blurry, low quality, deformed\"\n",
        "\n",
        "generated_images = img2img_generation(\n",
        "    image=init_image,\n",
        "    prompt=prompt,\n",
        "    negative_prompt=negative_prompt,\n",
        "    num_inference_steps=25,\n",
        "    guidance_scale=7.5,\n",
        "    strength=0.7\n",
        ")\n",
        "\n",
        "grid = image_grid(generated_images, rows=1, cols=1)\n",
        "plt.imshow(grid)\n",
        "plt.axis('off')\n",
        "plt.show()"
      ],
      "metadata": {
        "id": "PrI49jkhqlbt"
      },
      "execution_count": null,
      "outputs": []
    },
    {
      "cell_type": "code",
      "source": [
        "#@title ## **PLAY IMG2TEXT**\n",
        "from transformers import BlipProcessor, BlipForConditionalGeneration\n",
        "\n",
        "processor = BlipProcessor.from_pretrained(\"Salesforce/blip-image-captioning-base\")\n",
        "model = BlipForConditionalGeneration.from_pretrained(\"Salesforce/blip-image-captioning-base\").to(\"cuda\")\n",
        "\n",
        "img_url = 'https://storage.googleapis.com/sfr-vision-language-research/BLIP/demo.jpg' #@param {type:\"string\"}\n",
        "raw_image = Image.open(requests.get(img_url, stream=True).raw).convert('RGB')\n",
        "\n",
        "# conditional image captioning\n",
        "# text = \"a photography of\"\n",
        "# inputs = processor(raw_image, text, return_tensors=\"pt\").to(\"cuda\")\n",
        "\n",
        "# out = model.generate(**inputs)\n",
        "# print(processor.decode(out[0], skip_special_tokens=True))\n",
        "# # >>> a photography of a woman and her dog\n",
        "\n",
        "# unconditional image captioning\n",
        "inputs = processor(raw_image, return_tensors=\"pt\").to(\"cuda\")\n",
        "\n",
        "out = model.generate(**inputs)\n",
        "print(processor.decode(out[0], skip_special_tokens=True))"
      ],
      "metadata": {
        "id": "w2zvI2MCdkvI"
      },
      "execution_count": null,
      "outputs": []
    },
    {
      "cell_type": "code",
      "source": [
        "#@title # +**remove_file(s)**\n",
        "!rm \"/content/\"*.png\n",
        "prompt_num=prompt_num+1"
      ],
      "metadata": {
        "id": "43cmSm8zEEO1"
      },
      "execution_count": null,
      "outputs": []
    },
    {
      "cell_type": "code",
      "source": [
        "!rm f\"/content/{outputbase}{num-1}_{setseed}.png\""
      ],
      "metadata": {
        "id": "q6i9CLxwrXk3"
      },
      "execution_count": null,
      "outputs": []
    },
    {
      "cell_type": "code",
      "source": [
        "#@title #**3.0 CONNECT & SAVE TO GOOGLE DRIVE**\n",
        "from google.colab import drive\n",
        "import datetime\n",
        "\n",
        "drive.mount('/content/drive')\n",
        "\n",
        "x = datetime.datetime.now().strftime(\"%Y_%m_%d\")\n",
        "!mkdir \"/content/drive/MyDrive/Colab Notebooks/{x}\"\n",
        "!mkdir \"/content/drive/MyDrive/Colab Notebooks/{x}/prompt{prompt_num}\"\n",
        "\n",
        "!mv \"/content/outputs/\" \"/content/drive/MyDrive/Colab Notebooks/{x}/prompt{prompt_num}\"\n",
        "!mv \"/content/\"*.txt \"/content/drive/MyDrive/Colab Notebooks/{x}/prompt{prompt_num}\"\n",
        "\n",
        "prompt_num = prompt_num + 1"
      ],
      "metadata": {
        "id": "aFqO2Idf9bFr",
        "colab": {
          "base_uri": "https://localhost:8080/"
        },
        "outputId": "d14e7e19-91be-4554-b1d4-a9baddfbb663"
      },
      "execution_count": 87,
      "outputs": [
        {
          "output_type": "stream",
          "name": "stdout",
          "text": [
            "Drive already mounted at /content/drive; to attempt to forcibly remount, call drive.mount(\"/content/drive\", force_remount=True).\n",
            "mkdir: cannot create directory ‘/content/drive/MyDrive/Colab Notebooks/2025_05_10’: File exists\n"
          ]
        }
      ]
    },
    {
      "cell_type": "code",
      "source": [
        "!mv /content/dir {dir}"
      ],
      "metadata": {
        "id": "CluOv9T87XmH"
      },
      "execution_count": null,
      "outputs": []
    },
    {
      "cell_type": "code",
      "source": [
        "!mkdir outputs"
      ],
      "metadata": {
        "id": "6cSWetfP-gk5"
      },
      "execution_count": null,
      "outputs": []
    },
    {
      "cell_type": "code",
      "source": [
        "!mv \"/content/\"*.png \"/content/outputs\""
      ],
      "metadata": {
        "id": "j3jOiql0-pSz"
      },
      "execution_count": null,
      "outputs": []
    },
    {
      "cell_type": "code",
      "source": [
        "!smi-nvidia"
      ],
      "metadata": {
        "id": "foJEWcrREsiW"
      },
      "execution_count": null,
      "outputs": []
    },
    {
      "cell_type": "code",
      "source": [
        "#@title #**4.0 AUTOMATE PROMPTING (COMINGSOON)**\n",
        "\n",
        "class PromptStableDiffusion:\n",
        "    def __init__(self, subjek, gaya, latar_belakang, detail_tambahan):\n",
        "        self.subjek = subjek\n",
        "        self.gaya = gaya\n",
        "        self.latar_belakang = latar_belakang\n",
        "        self.detail_tambahan = detail_tambahan\n",
        "\n",
        "    def buat_prompt(self):\n",
        "        prompt = f\"{self.subjek}, {self.gaya}, latar belakang {self.latar_belakang}, {self.detail_tambahan}\"\n",
        "        return prompt\n",
        "\n",
        "prompt1 = PromptStableDiffusion(\n",
        "    subjek=\"seorang wanita muda\",\n",
        "    gaya=\"lukisan cat minyak impresionis\",\n",
        "    latar_belakang=\"taman bunga matahari yang luas\",\n",
        "    detail_tambahan=\"matahari terbenam, burung-burung terbang di kejauhan\"\n",
        ")\n",
        "\n",
        "prompt2 = PromptStableDiffusion(\n",
        "    subjek=\"seekor naga raksasa\",\n",
        "    gaya=\"fantasi gelap\",\n",
        "    latar_belakang=\"kastil kuno yang hancur\",\n",
        "    detail_tambahan=\"langit mendung, petir menyambar\"\n",
        ")\n",
        "\n",
        "daftar_prompt = [prompt1, prompt2]\n",
        "\n",
        "for prompt_obj in daftar_prompt:\n",
        "    print(prompt_obj.buat_prompt())\n",
        "\n",
        "\n",
        "\n",
        "import json\n",
        "daftar_prompt_json = [prompt_obj.__dict__ for prompt_obj in daftar_prompt]\n",
        "\n",
        "with open(\"prompt_stable_diffusion.json\", \"w\") as f:\n",
        "    json.dump(daftar_prompt_json, f, indent=4)\n",
        "\n",
        "print(\"\\nPrompt telah disimpan dalam file prompt_stable_diffusion.json\")"
      ],
      "metadata": {
        "id": "ZbfhpGRibfl6"
      },
      "execution_count": null,
      "outputs": []
    },
    {
      "cell_type": "code",
      "source": [
        "!export PYTORCH_CUDA_ALLOC_CONF=expandable_segments:True"
      ],
      "metadata": {
        "id": "1VAOxBU9wr5c"
      },
      "execution_count": 84,
      "outputs": []
    },
    {
      "cell_type": "code",
      "source": [
        "import os\n",
        "os.environ['PYTORCH_CUDA_ALLOC_CONF'] = 'expandable_segments:True'"
      ],
      "metadata": {
        "id": "eUFF5rSrwu_X"
      },
      "execution_count": 85,
      "outputs": []
    },
    {
      "cell_type": "markdown",
      "source": [
        "# **0.0 *~ ARCHIVE*** ~"
      ],
      "metadata": {
        "id": "lGvmIyA1g5o7"
      }
    },
    {
      "cell_type": "code",
      "source": [
        "!pip install numba\n",
        "from numba import cuda\n",
        "device = cuda.get_current_device()\n",
        "device.reset()"
      ],
      "metadata": {
        "id": "BJns1uUM8K1l"
      },
      "execution_count": null,
      "outputs": []
    },
    {
      "cell_type": "code",
      "source": [
        "#@markdown # Read Glosarium\n",
        "!git clone https://github.com/FreNzQuiN/GenerativeAI/blob/main/Stable_Diffusion/cheatsheet.md"
      ],
      "metadata": {
        "id": "126e2WN4o3EV"
      },
      "execution_count": null,
      "outputs": []
    },
    {
      "cell_type": "code",
      "source": [
        "!pip show diffusers"
      ],
      "metadata": {
        "id": "H6W7VGq1v1QV"
      },
      "execution_count": null,
      "outputs": []
    },
    {
      "cell_type": "code",
      "source": [
        "#@title # **2.1** *ARCHIVED*\n",
        "from compel import Compel, ReturnedEmbeddingsType\n",
        "import matplotlib.pyplot as plt\n",
        "from PIL import Image\n",
        "import random, time, math, os\n",
        "import torch, gc\n",
        "from tqdm import tqdm\n",
        "\n",
        "\n",
        "w = f\"/content/outputs\"\n",
        "if not os.path.exists(w):\n",
        "  !mkdir {w}\n",
        "\n",
        "def generate_image(pipe, prompt, negative_prompt, output_path, width, height, guidance_scale, guidance_rescale, num_inference_steps, seed):\n",
        "    \"\"\"Menghasilkan gambar Stable Diffusion.\"\"\"\n",
        "    image = pipe(\n",
        "        prompt=prompt,\n",
        "        negative_prompt=negative_prompt,\n",
        "        seed=seed,\n",
        "        width=width,\n",
        "        height=height,\n",
        "        guidance_scale=guidance_scale,\n",
        "        guidance_rescale=guidance_rescale,\n",
        "        target_size=(width, height),\n",
        "        original_size=(4096, 4096),\n",
        "        num_inference_steps=num_inference_steps,\n",
        "        truncation=True\n",
        "    ).images[0]\n",
        "    image.save(output_path)\n",
        "    return image\n",
        "\n",
        "def log_metadata(file_path, start_num, end_num, output_base, width, height, prompt, negative_prompt, guidance_scale, guidance_rescale, num_inference_steps, elapsed_time):\n",
        "    \"\"\"Mencatat metadata ke dalam file teks.\"\"\"\n",
        "    with open(file_path, \"a\") as text_file:\n",
        "        text_file.write(f\"\\n\\nTITLE: {start_num}--{end_num} {output_base} {width}x{height}px\\n + {prompt}\\n - {negative_prompt}\\n guide scale/rescale: {guidance_scale}/{guidance_rescale}\\n steps: {num_inference_steps}\\nIt took {math.floor(elapsed_time/60)} minutes {math.floor(elapsed_time%60)} seconds!\")\n",
        "\n",
        "\n",
        "amount = 50 #@param {type:'integer'}\n",
        "#@markdown ---\n",
        "char = \"(1girl, goldenglow \\\\(arknights)\\\\, arknights \\\\(series)\\\\)\" #@param {type:\"string\"}\n",
        "desc_char = \"close up, smirk, seducing expression, light blush, her outfit, mature teen, glow eyes, medium breast\" #@param {type:'string'}\n",
        "pov = \"looking at viewer, from front, depth of field\" # @param {\"type\":\"string\",\"placeholder\":\"dutch angle, looking at viewer, from front, depth of field, close up\"}\n",
        "bg = \" colorful, indoors, room, natural scenery\" # @param {\"type\":\"string\",\"placeholder\":\"colorful, indoors, natural scenery\"}\n",
        "style = \"masterpiece, high score, best quality, amazing quality, absurdres\" #@param {type:\"string\"}\n",
        "add = \"[light particles]\" #@param {type:\"string\"}\n",
        "rating = \"safe sensitive\" # @param [\"safe\",\"sensitive\"] {\"allow-input\":true}\n",
        "#@markdown ---\n",
        "prompt = f\"{style}, {char}, {rating}, {desc_char}, {pov}, {bg}, {add}\"\n",
        "negative_prompt = \" text,watermark,bad anatomy,bad proportions,extra limbs,extra digit,extra legs,extra legs and arms,disfigured,missing arms,too many fingers,fused fingers,missing fingers,unclear eyes,watermark,username\" #@param {type:'string'}\n",
        "#@markdown ---\n",
        "W = 960 #@param {type:\"slider\", min:512, max:2048, step:32}\n",
        "H = 1312 #@param {type:\"slider\", min:512, max:2048, step:32}\n",
        "guidance_scale = 5 #@param {type:'number'}\n",
        "guidance_rescale = 0.9 #@param {type:'number'}\n",
        "num_inference_steps = 32 #@param {type:\"slider\", min:10, max:40, step:1}\n",
        "#@markdown ---\n",
        "\n",
        "if len(char)>10 or (char[:1]==\"(\" and char[-1:]==\")\"):\n",
        "  nama_char = char.split(\", \")[1].split(\" \")[0]\n",
        "  jenis_char = char.split(\", \")[0][1:]\n",
        "outputname = \"anime\" #@param {type:'string'}\n",
        "ratingX = rating.split(\" \")[0]\n",
        "\n",
        "outputbase = f\"/content/outputs/{nama_char}_{ratingX}/{outputname}_{jenis_char}\"\n",
        "w = f\"/content/outputs/{nama_char}_{ratingX}\"\n",
        "if not os.path.exists(w):\n",
        "  !mkdir {w}\n",
        "rand = True #@param {type:'boolean'}\n",
        "if rand:\n",
        "  seed = 9999999 #@param {type:'integer'}\n",
        "startNum = num\n",
        "\n",
        "start_time = time.time()\n",
        "array_time = []\n",
        "\n",
        "for x in tqdm(range(amount), desc=f\"Generating Images {num}\"):\n",
        "    gc.collect()\n",
        "    torch.cuda.empty_cache()\n",
        "    image_start_time = time.time()\n",
        "    if rand:\n",
        "        set_seed = random.randint(100000, 100000000)\n",
        "    else:\n",
        "        set_seed = seed\n",
        "    output_file = f\"{outputbase}_{num}_{set_seed}_{rating}.png\"\n",
        "    image = generate_image(pipe, prompt, negative_prompt, output_file, W, H, guidance_scale, guidance_rescale, num_inference_steps, set_seed)\n",
        "    plt.imshow(image)\n",
        "    image_end_time = time.time()\n",
        "    array_time.append(image_end_time - image_start_time)\n",
        "    num += 1\n",
        "\n",
        "end_time = time.time()\n",
        "total_time = end_time - start_time\n",
        "log_metadata(f\"prompt{prompt_num}.txt\", startNum, num - 1, outputbase, W, H, prompt, negative_prompt, guidance_scale, guidance_rescale, num_inference_steps, total_time)\n",
        "\n",
        "gc.collect()\n",
        "torch.cuda.empty_cache()\n",
        "\n",
        "print(f\"It took {math.floor(total_time/60)} minutes {math.floor(total_time%60)} seconds!\")"
      ],
      "metadata": {
        "id": "K0v5K97whtNn",
        "cellView": "form"
      },
      "execution_count": null,
      "outputs": []
    },
    {
      "cell_type": "code",
      "source": [
        "#@title #**2.1 PLAY TEXT2IMG SD** *ARCHIVED*\n",
        "from compel import Compel, ReturnedEmbeddingsType\n",
        "import matplotlib.pyplot as plt\n",
        "from PIL import Image\n",
        "import random\n",
        "import time\n",
        "import math\n",
        "import torch, gc\n",
        "\n",
        "textFile = open(f\"prompt{prompt_num}.txt\", \"a\")\n",
        "\n",
        "amount = 5 #@param {type:'integer'}\n",
        "prompt = \"1girl, goldenglow \\(arknights\\), arknights \\(series\\), dutch angle, looking at viewer, cgdct, cute, solo, smile, light particles, casual, beautiful background, blush, outdoors, park, medium breast, from front, depth of field, very smooth line, year 2024, masterpiece, high score, great score, absurdres\" #@param {type:'string'}\n",
        "negative_prompt = \"lowres, bad anatomy, bad hands, text, error, missing finger, extra digits, fewer digits, cropped, worst quality, low quality, low score, bad score, average score, signature, watermark, username, blurry\" #@param {type:'string'}\n",
        "outputbase = \"/content/anime_girl\" #@param {type:'string'}\n",
        "startNum = num\n",
        "\n",
        "# compel = Compel(\n",
        "#   tokenizer=[pipe.tokenizer, pipe.tokenizer_2] ,\n",
        "#   text_encoder=[pipe.text_encoder, pipe.text_encoder_2],\n",
        "#   returned_embeddings_type=ReturnedEmbeddingsType.PENULTIMATE_HIDDEN_STATES_NON_NORMALIZED,\n",
        "#   requires_pooled=[False, True]\n",
        "# )\n",
        "# conditioning, pooled = compel(prompt)\n",
        "W = 1024 #@param {type:'integer'}\n",
        "H = 1424 #@param {type:'integer'}\n",
        "guidance_scale = 5 #@param {type:'number'}\n",
        "guidance_rescale = 0.9 #@param {type:'number'}\n",
        "num_inference_steps = 28 #@param {type:'integer'}\n",
        "rand = True #@param {type:'boolean'}\n",
        "start = time.time()\n",
        "arrayTime = []\n",
        "\n",
        "for x in range(amount):\n",
        "  gc.collect()\n",
        "  torch.cuda.empty_cache()\n",
        "  start = time.time()\n",
        "  if rand == True:\n",
        "    setseed = random.randint(100000,10000000)\n",
        "  else:\n",
        "    seed = 6 #@param {type:'integer'}\n",
        "    setseed = seed\n",
        "  image = pipe(\n",
        "      # prompt_embeds=conditioning, pooled_prompt_embeds=pooled,\n",
        "      prompt=prompt,\n",
        "      negative_prompt=negative_prompt,\n",
        "      seed=setseed,\n",
        "      width=W,\n",
        "      height=H,\n",
        "      guidance_scale=guidance_scale,\n",
        "      guidance_rescale=guidance_rescale,\n",
        "      target_size=(W,H),\n",
        "      original_size=(4096,4096),\n",
        "      num_inference_steps=num_inference_steps,\n",
        "      truncation=True\n",
        "      ).images[0]\n",
        "  output=f\"{outputbase}{num}_{setseed}.png\"\n",
        "  image.save(output)\n",
        "  image = Image.open(output)\n",
        "  plt.imshow(image)\n",
        "  end = time.time()\n",
        "  length = end - start\n",
        "  arrayTime.append(length)\n",
        "  num=num+1\n",
        "\n",
        "end = time.time()\n",
        "length = end - start\n",
        "print(\"It took\", math.floor(length/60), \"minutes\", math.floor(length%60), \"seconds!\")\n",
        "textFile.write(f\"\\n\\nTITLE: {startNum}--{num-1} {outputbase} {W}x{H}px\\n + {prompt}\\n - {negative_prompt}\\n guide scale/rescale: {guidance_scale}/{guidance_rescale}\\n steps: {num_inference_steps}\\nIt took {math.floor(length/60)} minutes {math.floor(length%60)} seconds!\")\n",
        "textFile.close()\n",
        "gc.collect()\n",
        "torch.cuda.empty_cache()"
      ],
      "metadata": {
        "id": "P69H37DAqHC8"
      },
      "execution_count": null,
      "outputs": []
    }
  ]
}