{
  "nbformat": 4,
  "nbformat_minor": 0,
  "metadata": {
    "colab": {
      "provenance": [],
      "gpuType": "T4",
      "include_colab_link": true
    },
    "kernelspec": {
      "name": "python3",
      "display_name": "Python 3"
    },
    "language_info": {
      "name": "python"
    },
    "accelerator": "GPU"
  },
  "cells": [
    {
      "cell_type": "markdown",
      "metadata": {
        "id": "view-in-github",
        "colab_type": "text"
      },
      "source": [
        "<a href=\"https://colab.research.google.com/github/FreNzQuiN/GenerativeAI/blob/main/Stable_Diffusion/MyLatestInlineSD.ipynb\" target=\"_parent\"><img src=\"https://colab.research.google.com/assets/colab-badge.svg\" alt=\"Open In Colab\"/></a>"
      ]
    },
    {
      "cell_type": "markdown",
      "source": [
        "# **1.1 START -- TEXT2IMG SD**"
      ],
      "metadata": {
        "id": "D3p5A4NPiKIN"
      }
    },
    {
      "cell_type": "code",
      "source": [
        "!pip install diffusers transformers accelerate safetensors compel --upgrade\n",
        "import torch\n",
        "from torch import autocast\n",
        "from diffusers import StableDiffusionXLPipeline, DDIMScheduler #EulerAncestralDiscreteScheduler,\n",
        "from compel import Compel, ReturnedEmbeddingsType\n",
        "import matplotlib.pyplot as plt\n",
        "from PIL import Image ImageFilter\n",
        "import random, time, math, os\n",
        "import torch, gc\n",
        "from tqdm import tqdm\n",
        "import requests\n",
        "from io import BytesIO\n",
        "\n",
        "if not os.path.exists(\"scheduler_config.json\"):\n",
        "  !wget https://huggingface.co/cagliostrolab/animagine-xl-4.0/resolve/main/scheduler/scheduler_config.json\n",
        "\n",
        "custom_config = True #@param {type:'boolean'}\n",
        "if os.path.exists(\"scheduler_config.json\") and not custom_config:\n",
        "  with open(\"scheduler_config.json\", \"r\") as f:\n",
        "    scheduler_config = json.load(f)\n",
        "else:\n",
        "  scheduler_config = {\n",
        "    \"beta_start\": 0.00085,\n",
        "    \"beta_end\": 0.012,\n",
        "    \"num_train_timesteps\": 1000,\n",
        "    \"steps_offset\" : 2,\n",
        "    \"beta_schedule\": \"scaled_linear\",\n",
        "    \"clip_sample\": False,\n",
        "    \"set_alpha_to_one\": False,\n",
        "    \"_class_name\": \"DDIMScheduler\",\n",
        "    \"_diffusers_version\": \"0.32.2\"\n",
        "  }\n",
        "\n",
        "pipe = StableDiffusionXLPipeline.from_pretrained(\n",
        "    \"cagliostrolab/animagine-xl-4.0\",\n",
        "    torch_dtype=torch.float16,\n",
        "    use_safetensors=True,\n",
        "    custom_pipeline=\"lpw_stable_diffusion_xl\",\n",
        "    add_watermarker=False,\n",
        "    )\n",
        "\n",
        "pipe.scheduler = DDIMScheduler.from_config(scheduler_config)\n",
        "pipe.to('cuda')\n"
      ],
      "metadata": {
        "id": "yOZXfJRCqFg0"
      },
      "execution_count": null,
      "outputs": []
    },
    {
      "cell_type": "code",
      "source": [
        "#@title #**1.2 START -- IMG2IMG SD**\n",
        "!pip install diffusers transformers accelerate safetensors compel --upgrade\n",
        "import torch\n",
        "from torch import autocast\n",
        "from diffusers import StableDiffusionXLPipeline, DDIMScheduler\n",
        "from compel import Compel, ReturnedEmbeddingsType\n",
        "import matplotlib.pyplot as plt\n",
        "from PIL import Image, ImageFilter\n",
        "import random, time, math, os\n",
        "import torch, gc\n",
        "from tqdm import tqdm\n",
        "import json\n",
        "import requests\n",
        "from io import BytesIO\n",
        "\n",
        "if not os.path.exists(\"scheduler_config.json\"):\n",
        "    !wget https://huggingface.co/cagliostrolab/animagine-xl-4.0/resolve/main/scheduler/scheduler_config.json\n",
        "\n",
        "custom_config = True  # @param {type:'boolean'}\n",
        "if os.path.exists(\"scheduler_config.json\") and not custom_config:\n",
        "    with open(\"scheduler_config.json\", \"r\") as f:\n",
        "        scheduler_config = json.load(f)\n",
        "else:\n",
        "    scheduler_config = {\n",
        "        \"beta_start\": 0.00085,\n",
        "        \"beta_end\": 0.012,\n",
        "        \"num_train_timesteps\": 1000,\n",
        "        \"steps_offset\": 2,\n",
        "        \"beta_schedule\": \"scaled_linear\",\n",
        "        \"clip_sample\": False,\n",
        "        \"set_alpha_to_one\": False,\n",
        "        \"_class_name\": \"DDIMScheduler\",\n",
        "        \"_diffusers_version\": \"0.32.2\"\n",
        "    }\n",
        "\n",
        "pipe = StableDiffusionXLPipeline.from_pretrained(\n",
        "    \"cagliostrolab/animagine-xl-4.0\",\n",
        "    torch_dtype=torch.float16,\n",
        "    use_safetensors=True,\n",
        "    custom_pipeline=\"lpw_stable_diffusion_xl\",\n",
        "    add_watermarker=False,\n",
        ")\n",
        "\n",
        "pipe.scheduler = DDIMScheduler.from_config(scheduler_config)\n",
        "pipe.to('cuda')"
      ],
      "metadata": {
        "id": "EgM8KpjQpmn9"
      },
      "execution_count": null,
      "outputs": []
    },
    {
      "cell_type": "code",
      "source": [
        "#@title #**2.1 PLAY TEXT2IMG SD**\n",
        "num=0\n",
        "prompt_num=0\n",
        "def disabled_safety_checker(images, clip_input):\n",
        "    if len(images.shape)==4:\n",
        "        num_images = images.shape[0]\n",
        "        return images, [False]*num_images\n",
        "    else:\n",
        "        return images, False\n",
        "pipe.safety_checker = disabled_safety_checker"
      ],
      "metadata": {
        "id": "TX5cV32X0-yJ"
      },
      "execution_count": null,
      "outputs": []
    },
    {
      "cell_type": "code",
      "source": [
        "w = f\"/content/outputs\"\n",
        "if not os.path.exists(w):\n",
        "    os.makedirs(w)\n",
        "\n",
        "def generate_image(pipe, prompt, negative_prompt, output_path, width, height, guidance_scale, guidance_rescale, num_inference_steps, seed):\n",
        "    \"\"\"Menghasilkan gambar Stable Diffusion.\"\"\"\n",
        "    image = pipe(\n",
        "        prompt=prompt,\n",
        "        negative_prompt=negative_prompt,\n",
        "        seed=seed,\n",
        "        width=width,\n",
        "        height=height,\n",
        "        guidance_scale=guidance_scale,\n",
        "        guidance_rescale=guidance_rescale,\n",
        "        target_size=(width, height),\n",
        "        original_size=(4096, 4096),\n",
        "        num_inference_steps=num_inference_steps,\n",
        "        truncation=True\n",
        "    ).images[0]\n",
        "    image.save(output_path, \"png\", lossless=True, quality=100)\n",
        "    return image\n",
        "\n",
        "def log_metadata(file_path, start_num, end_num, output_base, width, height, style, char, rating, desc_char, pov, bg, add, negative_prompt, guidance_scale, guidance_rescale, num_inference_steps, elapsed_time):\n",
        "    \"\"\"Mencatat metadata ke dalam file teks.\"\"\"\n",
        "    with open(file_path, \"a\") as text_file:\n",
        "        text_file.write(f\"\\n\\nTITLE: {start_num}--{end_num} {output_base} {width}x{height}px\\n + {style},\\n {char},\\n {rating},\\n {desc_char},\\n {pov},\\n {bg},\\n {add}\\n - {negative_prompt}\\n guide scale/rescale: {guidance_scale}/{guidance_rescale}\\n steps: {num_inference_steps}\\nIt took {math.floor(elapsed_time/60)} minutes {math.floor(elapsed_time%60)} seconds!\")\n",
        "\n",
        "amount = 50 #@param {type:'integer'}\n",
        "#@markdown ---\n",
        "char = \"(1girl, princess, snow white long hair with light blue effect, red amber eyes)\" #@param {type:\"string\"}\n",
        "desc_char = \"seducing, cute, sweating, light blush, [casual outfit:0.6, short skirt:0.7], air blow, teen, glow eyes, medium breast\" #@param {type:'string'}\n",
        "pov = \"looking at viewer, close up, from front, depth of field, [clear view]\" # @param {\"type\":\"string\",\"placeholder\":\"dutch angle, looking at viewer, from front, depth of field, close up\"}\n",
        "bg = \" colorful:0.7, [green garden, tree:0.3], outdoors, natural scenery, [highlight:0.2]\" # @param {\"type\":\"string\",\"placeholder\":\"colorful, indoors, natural scenery\"}\n",
        "style = \"masterpiece, high score, best quality, absurdres, [vibrant, very aesthetic, high detail], masterful composition\" # @param {\"type\":\"string\",\"placeholder\":\"masterpiece, high score, best quality, amazing quality, absurdres, [vibrant, very aesthetic, high contrast], masterful composition\"}\n",
        "add = \"[light light particles:0.2], [morning fog:0.2]\" #@param {type:\"string\"}\n",
        "rating = \"sensitive\" # @param [\"safe\",\"sensitive\"] {\"allow-input\":true}\n",
        "#@markdown ---\n",
        "prompt = f\"{style}, {char}, {rating}, {desc_char}, {pov}, {bg}, {add}\"\n",
        "negative_prompt = \"nude, femboy, text, watermark, bad anatomy, bad proportions, extra limbs, extra digit, extra legs, extra legs and arms, disfigured, missing arms, too many fingers, fused fingers, missing fingers, unclear eyes, watermark, username\" #@param {type:'string'}\n",
        "\n",
        "#@markdown ---\n",
        "W = 960 #@param {type:\"slider\", min:512, max:2048, step:32}\n",
        "H = 1216 #@param {type:\"slider\", min:512, max:2048, step:32}\n",
        "swapWH = False # @param {\"type\":\"boolean\"}\n",
        "if swapWH:\n",
        "  W, H = H, W\n",
        "#@markdown ---\n",
        "guidance_scale = 5.3 #@param {type:'number'}\n",
        "guidance_rescale = 0.87 #@param {type:'number'}\n",
        "num_inference_steps = 32 #@param {type:\"slider\", min:10, max:40, step:1}\n",
        "#@markdown ---\n",
        "\n",
        "if len(char) > 10 or (char[:1] == \"(\" and char[-1:] == \")\"):\n",
        "    nama_char = char.split(\", \")[1].split(\" \")[0]\n",
        "    jenis_char = char.split(\", \")[0][1:]\n",
        "outputname = \"anime\" #@param {type:'string'}\n",
        "ratingX = rating.split(\" \")[0]\n",
        "\n",
        "outputbase = f\"/content/outputs/{nama_char}_{ratingX}/{outputname}_{jenis_char}\"\n",
        "w = f\"/content/outputs/{nama_char}_{ratingX}\"\n",
        "if not os.path.exists(w):\n",
        "    os.makedirs(w)\n",
        "rand = True #@param {type:'boolean'}\n",
        "if rand:\n",
        "    seed = 9999999 #@param {type:'integer'}\n",
        "startNum = num\n",
        "\n",
        "start_time = time.time()\n",
        "array_time = []\n",
        "\n",
        "for x in tqdm(range(amount), desc=f\"Generating Images {num}\"):\n",
        "    gc.collect()\n",
        "    torch.cuda.empty_cache()\n",
        "    image_start_time = time.time()\n",
        "    if rand:\n",
        "        set_seed = random.randint(100000, 100000000)\n",
        "    else:\n",
        "        set_seed = seed\n",
        "    output_file = f\"{outputbase}_{num}_{set_seed}_{rating}.webp\"\n",
        "    image = generate_image(pipe, prompt, negative_prompt, output_file, W, H, guidance_scale, guidance_rescale, num_inference_steps, set_seed)\n",
        "    blurred_image = image.filter(ImageFilter.GaussianBlur(radius=25))\n",
        "    if \"nsfw\" in rating or \"explicit\" in rating:\n",
        "      plt.imshow(blurred_image)\n",
        "    else :\n",
        "      plt.imshow(image)\n",
        "    plt.axis('off')\n",
        "    plt.show()\n",
        "    image_end_time = time.time()\n",
        "    array_time.append(image_end_time - image_start_time)\n",
        "    num += 1\n",
        "\n",
        "end_time = time.time()\n",
        "total_time = end_time - start_time\n",
        "log_metadata(f\"prompt_{prompt_num}.txt\", startNum, num - 1, outputbase, W, H, style, char, rating, desc_char, pov, bg, add, negative_prompt, guidance_scale, guidance_rescale, num_inference_steps, total_time)\n",
        "\n",
        "gc.collect()\n",
        "torch.cuda.empty_cache()\n",
        "\n",
        "print(f\"It took {math.floor(total_time/60)} minutes {math.floor(total_time%60)} seconds!\")"
      ],
      "metadata": {
        "id": "8Ta3AnCph0Mb",
        "cellView": "form"
      },
      "execution_count": null,
      "outputs": []
    },
    {
      "cell_type": "code",
      "source": [
        "#@title +load_lora\n",
        "\n",
        "lora_path = \"/path/to/your/lora.safetensors\"\n",
        "print(f\"Memasang LoRA dari: {lora_path}\")\n",
        "pipe.load_lora_weights(lora_path)"
      ],
      "metadata": {
        "id": "O7qLIXKRlUGe"
      },
      "execution_count": null,
      "outputs": []
    },
    {
      "cell_type": "code",
      "source": [
        "#@title +unload_lora\n",
        "\n",
        "print(\"Melepas LoRA\")\n",
        "pipe.unload_lora_weights()"
      ],
      "metadata": {
        "id": "k3HAgwYMB7RN"
      },
      "execution_count": null,
      "outputs": []
    },
    {
      "cell_type": "code",
      "source": [
        "#@title ##**Tagger**\n",
        "#!git clone https://github.com/neggles/wdv3-timm.git\n",
        "#!pip install -q -r \"/content/wdv3-timm/requirements.txt\"\n",
        "!curl -o wd14-tagger.py https://raw.githubusercontent.com/FreNzQuiN/GenerativeAI/refs/heads/main/Stable_Diffusion/wd14-tagger.py\n"
      ],
      "metadata": {
        "id": "25mGDN6ksl-M"
      },
      "execution_count": null,
      "outputs": []
    },
    {
      "cell_type": "code",
      "source": [
        "# Run\n",
        "# <swinv2|convnext|vit>\n",
        "path = \"/content/outputs/princess_sensitive/anime_1girl_148_68361693_sensitive.webp\" # @param [] {\"allow-input\":true}\n",
        "#!python /content/wdv3-timm/wdv3_timm.py <swinv2|convnext|vit> {path}\n",
        "!python /content/wd14-tagger.py {path}"
      ],
      "metadata": {
        "id": "D7w69wWd1gZ5"
      },
      "execution_count": null,
      "outputs": []
    },
    {
      "cell_type": "code",
      "source": [
        "#@title ##**2.2 PLAY IMG2IMG**\n",
        "def image_grid(imgs, rows, cols):\n",
        "    assert len(imgs) == rows * cols\n",
        "\n",
        "    w, h = imgs[0].size\n",
        "    grid = Image.new('RGB', size=(cols * w, rows * h))\n",
        "    grid_w, grid_h = grid.size\n",
        "\n",
        "    for i, img in enumerate(imgs):\n",
        "        grid.paste(img, box=(i % cols * w, i // cols * h))\n",
        "    return grid\n",
        "\n",
        "def download_image(url):\n",
        "    response = requests.get(url)\n",
        "    return Image.open(BytesIO(response.content)).convert(\"RGB\")\n",
        "\n",
        "def img2img_generation(image, prompt, negative_prompt, num_inference_steps=25, guidance_scale=7.5, strength=0.7):\n",
        "    images = pipe(\n",
        "        prompt=prompt,\n",
        "        negative_prompt=negative_prompt,\n",
        "        image=image,\n",
        "        num_inference_steps=num_inference_steps,\n",
        "        guidance_scale=guidance_scale,\n",
        "        strength=strength,\n",
        "    ).images\n",
        "    return images\n",
        "\n",
        "# Contoh Penggunaan img2img\n",
        "image_url = \"https://huggingface.co/datasets/hf-internal-testing/diffusers-images/resolve/main/sd_xl/input_1024x1024.png\"\n",
        "init_image = download_image(image_url)\n",
        "\n",
        "prompt = \"A futuristic city skyline, neon lights, cyberpunk style\"\n",
        "negative_prompt = \"blurry, low quality, deformed\"\n",
        "\n",
        "generated_images = img2img_generation(\n",
        "    image=init_image,\n",
        "    prompt=prompt,\n",
        "    negative_prompt=negative_prompt,\n",
        "    num_inference_steps=25,\n",
        "    guidance_scale=7.5,\n",
        "    strength=0.7\n",
        ")\n",
        "\n",
        "grid = image_grid(generated_images, rows=1, cols=1)\n",
        "plt.imshow(grid)\n",
        "plt.axis('off')\n",
        "plt.show()"
      ],
      "metadata": {
        "id": "PrI49jkhqlbt"
      },
      "execution_count": null,
      "outputs": []
    },
    {
      "cell_type": "code",
      "source": [
        "#@title ## **PLAY IMG2TEXT**\n",
        "from transformers import BlipProcessor, BlipForConditionalGeneration\n",
        "\n",
        "processor = BlipProcessor.from_pretrained(\"Salesforce/blip-image-captioning-base\")\n",
        "model = BlipForConditionalGeneration.from_pretrained(\"Salesforce/blip-image-captioning-base\").to(\"cuda\")\n",
        "\n",
        "img_url = 'https://storage.googleapis.com/sfr-vision-language-research/BLIP/demo.jpg' #@param {type:\"string\"}\n",
        "raw_image = Image.open(requests.get(img_url, stream=True).raw).convert('RGB')\n",
        "\n",
        "# conditional image captioning\n",
        "# text = \"a photography of\"\n",
        "# inputs = processor(raw_image, text, return_tensors=\"pt\").to(\"cuda\")\n",
        "\n",
        "# out = model.generate(**inputs)\n",
        "# print(processor.decode(out[0], skip_special_tokens=True))\n",
        "# # >>> a photography of a woman and her dog\n",
        "\n",
        "# unconditional image captioning\n",
        "inputs = processor(raw_image, return_tensors=\"pt\").to(\"cuda\")\n",
        "\n",
        "out = model.generate(**inputs)\n",
        "print(processor.decode(out[0], skip_special_tokens=True))"
      ],
      "metadata": {
        "id": "w2zvI2MCdkvI"
      },
      "execution_count": null,
      "outputs": []
    },
    {
      "cell_type": "code",
      "source": [
        "#@title # +**remove_file(s)**\n",
        "!rm \"/content/\"*.png\n",
        "prompt_num=prompt_num+1"
      ],
      "metadata": {
        "id": "43cmSm8zEEO1"
      },
      "execution_count": null,
      "outputs": []
    },
    {
      "cell_type": "code",
      "source": [
        "!rm f\"/content/{outputbase}{num-1}_{setseed}.png\""
      ],
      "metadata": {
        "id": "q6i9CLxwrXk3"
      },
      "execution_count": null,
      "outputs": []
    },
    {
      "cell_type": "code",
      "source": [
        "#@title #**3.0 CONNECT & SAVE TO GOOGLE DRIVE**\n",
        "from google.colab import drive\n",
        "import datetime\n",
        "\n",
        "drive.mount('/content/drive')\n",
        "\n",
        "x = datetime.datetime.now().strftime(\"%Y_%m_%d\")\n",
        "!mkdir \"/content/drive/MyDrive/Colab Notebooks/{x}\"\n",
        "!mkdir \"/content/drive/MyDrive/Colab Notebooks/{x}/prompt{prompt_num}\"\n",
        "\n",
        "!mv \"/content/outputs/\" \"/content/drive/MyDrive/Colab Notebooks/{x}/prompt{prompt_num}\"\n",
        "!mv \"/content/\"*.txt \"/content/drive/MyDrive/Colab Notebooks/{x}/prompt{prompt_num}\"\n",
        "\n",
        "prompt_num = prompt_num + 1"
      ],
      "metadata": {
        "id": "aFqO2Idf9bFr"
      },
      "execution_count": null,
      "outputs": []
    },
    {
      "cell_type": "code",
      "source": [
        "!mv /content/dir {dir}"
      ],
      "metadata": {
        "id": "CluOv9T87XmH"
      },
      "execution_count": null,
      "outputs": []
    },
    {
      "cell_type": "code",
      "source": [
        "!mkdir outputs"
      ],
      "metadata": {
        "id": "6cSWetfP-gk5"
      },
      "execution_count": null,
      "outputs": []
    },
    {
      "cell_type": "code",
      "source": [
        "!mv \"/content/\"*.png \"/content/outputs\""
      ],
      "metadata": {
        "id": "j3jOiql0-pSz"
      },
      "execution_count": null,
      "outputs": []
    },
    {
      "cell_type": "code",
      "source": [
        "!smi-nvidia"
      ],
      "metadata": {
        "id": "foJEWcrREsiW"
      },
      "execution_count": null,
      "outputs": []
    },
    {
      "cell_type": "code",
      "source": [
        "#@title #**4.0 AUTOMATE PROMPTING (COMINGSOON)**\n",
        "\n",
        "class PromptStableDiffusion:\n",
        "    def __init__(self, subjek, gaya, latar_belakang, detail_tambahan):\n",
        "        self.subjek = subjek\n",
        "        self.gaya = gaya\n",
        "        self.latar_belakang = latar_belakang\n",
        "        self.detail_tambahan = detail_tambahan\n",
        "\n",
        "    def buat_prompt(self):\n",
        "        prompt = f\"{self.subjek}, {self.gaya}, latar belakang {self.latar_belakang}, {self.detail_tambahan}\"\n",
        "        return prompt\n",
        "\n",
        "prompt1 = PromptStableDiffusion(\n",
        "    subjek=\"seorang wanita muda\",\n",
        "    gaya=\"lukisan cat minyak impresionis\",\n",
        "    latar_belakang=\"taman bunga matahari yang luas\",\n",
        "    detail_tambahan=\"matahari terbenam, burung-burung terbang di kejauhan\"\n",
        ")\n",
        "\n",
        "prompt2 = PromptStableDiffusion(\n",
        "    subjek=\"seekor naga raksasa\",\n",
        "    gaya=\"fantasi gelap\",\n",
        "    latar_belakang=\"kastil kuno yang hancur\",\n",
        "    detail_tambahan=\"langit mendung, petir menyambar\"\n",
        ")\n",
        "\n",
        "daftar_prompt = [prompt1, prompt2]\n",
        "\n",
        "for prompt_obj in daftar_prompt:\n",
        "    print(prompt_obj.buat_prompt())\n",
        "\n",
        "\n",
        "\n",
        "import json\n",
        "daftar_prompt_json = [prompt_obj.__dict__ for prompt_obj in daftar_prompt]\n",
        "\n",
        "with open(\"prompt_stable_diffusion.json\", \"w\") as f:\n",
        "    json.dump(daftar_prompt_json, f, indent=4)\n",
        "\n",
        "print(\"\\nPrompt telah disimpan dalam file prompt_stable_diffusion.json\")"
      ],
      "metadata": {
        "id": "ZbfhpGRibfl6"
      },
      "execution_count": null,
      "outputs": []
    },
    {
      "cell_type": "markdown",
      "source": [
        "# **0.0 *~ ARCHIVE*** ~"
      ],
      "metadata": {
        "id": "lGvmIyA1g5o7"
      }
    },
    {
      "cell_type": "code",
      "source": [
        "!pip install numba\n",
        "from numba import cuda\n",
        "device = cuda.get_current_device()\n",
        "device.reset()"
      ],
      "metadata": {
        "id": "BJns1uUM8K1l"
      },
      "execution_count": null,
      "outputs": []
    },
    {
      "cell_type": "code",
      "source": [
        "#@markdown # Read Glosarium\n",
        "!git clone https://github.com/FreNzQuiN/GenerativeAI/blob/main/Stable_Diffusion/cheatsheet.md"
      ],
      "metadata": {
        "id": "126e2WN4o3EV"
      },
      "execution_count": null,
      "outputs": []
    },
    {
      "cell_type": "code",
      "source": [
        "!pip show diffusers"
      ],
      "metadata": {
        "id": "H6W7VGq1v1QV"
      },
      "execution_count": null,
      "outputs": []
    },
    {
      "cell_type": "code",
      "source": [
        "#@title # **2.1** *ARCHIVED*\n",
        "from compel import Compel, ReturnedEmbeddingsType\n",
        "import matplotlib.pyplot as plt\n",
        "from PIL import Image\n",
        "import random, time, math, os\n",
        "import torch, gc\n",
        "from tqdm import tqdm\n",
        "\n",
        "\n",
        "w = f\"/content/outputs\"\n",
        "if not os.path.exists(w):\n",
        "  !mkdir {w}\n",
        "\n",
        "def generate_image(pipe, prompt, negative_prompt, output_path, width, height, guidance_scale, guidance_rescale, num_inference_steps, seed):\n",
        "    \"\"\"Menghasilkan gambar Stable Diffusion.\"\"\"\n",
        "    image = pipe(\n",
        "        prompt=prompt,\n",
        "        negative_prompt=negative_prompt,\n",
        "        seed=seed,\n",
        "        width=width,\n",
        "        height=height,\n",
        "        guidance_scale=guidance_scale,\n",
        "        guidance_rescale=guidance_rescale,\n",
        "        target_size=(width, height),\n",
        "        original_size=(4096, 4096),\n",
        "        num_inference_steps=num_inference_steps,\n",
        "        truncation=True\n",
        "    ).images[0]\n",
        "    image.save(output_path)\n",
        "    return image\n",
        "\n",
        "def log_metadata(file_path, start_num, end_num, output_base, width, height, prompt, negative_prompt, guidance_scale, guidance_rescale, num_inference_steps, elapsed_time):\n",
        "    \"\"\"Mencatat metadata ke dalam file teks.\"\"\"\n",
        "    with open(file_path, \"a\") as text_file:\n",
        "        text_file.write(f\"\\n\\nTITLE: {start_num}--{end_num} {output_base} {width}x{height}px\\n + {prompt}\\n - {negative_prompt}\\n guide scale/rescale: {guidance_scale}/{guidance_rescale}\\n steps: {num_inference_steps}\\nIt took {math.floor(elapsed_time/60)} minutes {math.floor(elapsed_time%60)} seconds!\")\n",
        "\n",
        "\n",
        "amount = 50 #@param {type:'integer'}\n",
        "#@markdown ---\n",
        "char = \"(1girl, goldenglow \\\\(arknights)\\\\, arknights \\\\(series)\\\\)\" #@param {type:\"string\"}\n",
        "desc_char = \"close up, smirk, seducing expression, light blush, her outfit, mature teen, glow eyes, medium breast\" #@param {type:'string'}\n",
        "pov = \"looking at viewer, from front, depth of field\" # @param {\"type\":\"string\",\"placeholder\":\"dutch angle, looking at viewer, from front, depth of field, close up\"}\n",
        "bg = \" colorful, indoors, room, natural scenery\" # @param {\"type\":\"string\",\"placeholder\":\"colorful, indoors, natural scenery\"}\n",
        "style = \"masterpiece, high score, best quality, amazing quality, absurdres\" #@param {type:\"string\"}\n",
        "add = \"[light particles]\" #@param {type:\"string\"}\n",
        "rating = \"safe sensitive\" # @param [\"safe\",\"sensitive\"] {\"allow-input\":true}\n",
        "#@markdown ---\n",
        "prompt = f\"{style}, {char}, {rating}, {desc_char}, {pov}, {bg}, {add}\"\n",
        "negative_prompt = \" text,watermark,bad anatomy,bad proportions,extra limbs,extra digit,extra legs,extra legs and arms,disfigured,missing arms,too many fingers,fused fingers,missing fingers,unclear eyes,watermark,username\" #@param {type:'string'}\n",
        "#@markdown ---\n",
        "W = 960 #@param {type:\"slider\", min:512, max:2048, step:32}\n",
        "H = 1312 #@param {type:\"slider\", min:512, max:2048, step:32}\n",
        "guidance_scale = 5 #@param {type:'number'}\n",
        "guidance_rescale = 0.9 #@param {type:'number'}\n",
        "num_inference_steps = 32 #@param {type:\"slider\", min:10, max:40, step:1}\n",
        "#@markdown ---\n",
        "\n",
        "if len(char)>10 or (char[:1]==\"(\" and char[-1:]==\")\"):\n",
        "  nama_char = char.split(\", \")[1].split(\" \")[0]\n",
        "  jenis_char = char.split(\", \")[0][1:]\n",
        "outputname = \"anime\" #@param {type:'string'}\n",
        "ratingX = rating.split(\" \")[0]\n",
        "\n",
        "outputbase = f\"/content/outputs/{nama_char}_{ratingX}/{outputname}_{jenis_char}\"\n",
        "w = f\"/content/outputs/{nama_char}_{ratingX}\"\n",
        "if not os.path.exists(w):\n",
        "  !mkdir {w}\n",
        "rand = True #@param {type:'boolean'}\n",
        "if rand:\n",
        "  seed = 9999999 #@param {type:'integer'}\n",
        "startNum = num\n",
        "\n",
        "start_time = time.time()\n",
        "array_time = []\n",
        "\n",
        "for x in tqdm(range(amount), desc=f\"Generating Images {num}\"):\n",
        "    gc.collect()\n",
        "    torch.cuda.empty_cache()\n",
        "    image_start_time = time.time()\n",
        "    if rand:\n",
        "        set_seed = random.randint(100000, 100000000)\n",
        "    else:\n",
        "        set_seed = seed\n",
        "    output_file = f\"{outputbase}_{num}_{set_seed}_{rating}.png\"\n",
        "    image = generate_image(pipe, prompt, negative_prompt, output_file, W, H, guidance_scale, guidance_rescale, num_inference_steps, set_seed)\n",
        "    plt.imshow(image)\n",
        "    image_end_time = time.time()\n",
        "    array_time.append(image_end_time - image_start_time)\n",
        "    num += 1\n",
        "\n",
        "end_time = time.time()\n",
        "total_time = end_time - start_time\n",
        "log_metadata(f\"prompt{prompt_num}.txt\", startNum, num - 1, outputbase, W, H, prompt, negative_prompt, guidance_scale, guidance_rescale, num_inference_steps, total_time)\n",
        "\n",
        "gc.collect()\n",
        "torch.cuda.empty_cache()\n",
        "\n",
        "print(f\"It took {math.floor(total_time/60)} minutes {math.floor(total_time%60)} seconds!\")"
      ],
      "metadata": {
        "id": "K0v5K97whtNn",
        "cellView": "form"
      },
      "execution_count": null,
      "outputs": []
    },
    {
      "cell_type": "code",
      "source": [
        "#@title #**2.1 PLAY TEXT2IMG SD** *ARCHIVED*\n",
        "from compel import Compel, ReturnedEmbeddingsType\n",
        "import matplotlib.pyplot as plt\n",
        "from PIL import Image\n",
        "import random\n",
        "import time\n",
        "import math\n",
        "import torch, gc\n",
        "\n",
        "textFile = open(f\"prompt{prompt_num}.txt\", \"a\")\n",
        "\n",
        "amount = 5 #@param {type:'integer'}\n",
        "prompt = \"1girl, goldenglow \\(arknights\\), arknights \\(series\\), dutch angle, looking at viewer, cgdct, cute, solo, smile, light particles, casual, beautiful background, blush, outdoors, park, medium breast, from front, depth of field, very smooth line, year 2024, masterpiece, high score, great score, absurdres\" #@param {type:'string'}\n",
        "negative_prompt = \"lowres, bad anatomy, bad hands, text, error, missing finger, extra digits, fewer digits, cropped, worst quality, low quality, low score, bad score, average score, signature, watermark, username, blurry\" #@param {type:'string'}\n",
        "outputbase = \"/content/anime_girl\" #@param {type:'string'}\n",
        "startNum = num\n",
        "\n",
        "# compel = Compel(\n",
        "#   tokenizer=[pipe.tokenizer, pipe.tokenizer_2] ,\n",
        "#   text_encoder=[pipe.text_encoder, pipe.text_encoder_2],\n",
        "#   returned_embeddings_type=ReturnedEmbeddingsType.PENULTIMATE_HIDDEN_STATES_NON_NORMALIZED,\n",
        "#   requires_pooled=[False, True]\n",
        "# )\n",
        "# conditioning, pooled = compel(prompt)\n",
        "W = 1024 #@param {type:'integer'}\n",
        "H = 1424 #@param {type:'integer'}\n",
        "guidance_scale = 5 #@param {type:'number'}\n",
        "guidance_rescale = 0.9 #@param {type:'number'}\n",
        "num_inference_steps = 28 #@param {type:'integer'}\n",
        "rand = True #@param {type:'boolean'}\n",
        "start = time.time()\n",
        "arrayTime = []\n",
        "\n",
        "for x in range(amount):\n",
        "  gc.collect()\n",
        "  torch.cuda.empty_cache()\n",
        "  start = time.time()\n",
        "  if rand == True:\n",
        "    setseed = random.randint(100000,10000000)\n",
        "  else:\n",
        "    seed = 6 #@param {type:'integer'}\n",
        "    setseed = seed\n",
        "  image = pipe(\n",
        "      # prompt_embeds=conditioning, pooled_prompt_embeds=pooled,\n",
        "      prompt=prompt,\n",
        "      negative_prompt=negative_prompt,\n",
        "      seed=setseed,\n",
        "      width=W,\n",
        "      height=H,\n",
        "      guidance_scale=guidance_scale,\n",
        "      guidance_rescale=guidance_rescale,\n",
        "      target_size=(W,H),\n",
        "      original_size=(4096,4096),\n",
        "      num_inference_steps=num_inference_steps,\n",
        "      truncation=True\n",
        "      ).images[0]\n",
        "  output=f\"{outputbase}{num}_{setseed}.png\"\n",
        "  image.save(output)\n",
        "  image = Image.open(output)\n",
        "  plt.imshow(image)\n",
        "  end = time.time()\n",
        "  length = end - start\n",
        "  arrayTime.append(length)\n",
        "  num=num+1\n",
        "\n",
        "end = time.time()\n",
        "length = end - start\n",
        "print(\"It took\", math.floor(length/60), \"minutes\", math.floor(length%60), \"seconds!\")\n",
        "textFile.write(f\"\\n\\nTITLE: {startNum}--{num-1} {outputbase} {W}x{H}px\\n + {prompt}\\n - {negative_prompt}\\n guide scale/rescale: {guidance_scale}/{guidance_rescale}\\n steps: {num_inference_steps}\\nIt took {math.floor(length/60)} minutes {math.floor(length%60)} seconds!\")\n",
        "textFile.close()\n",
        "gc.collect()\n",
        "torch.cuda.empty_cache()"
      ],
      "metadata": {
        "id": "P69H37DAqHC8"
      },
      "execution_count": null,
      "outputs": []
    }
  ]
}